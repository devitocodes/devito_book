{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Diffusion in 2D\n",
    "<div id=\"diffu:2D\"></div>\n",
    "\n",
    "We now address diffusion in two space dimensions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto1\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\frac{\\partial u}{\\partial t}  = \\dfc\\left(\n",
    "\\frac{\\partial^2 u}{\\partial x^2} +\n",
    "\\frac{\\partial^2 u}{\\partial x^2}\\right) + f(x,y),\n",
    "\\label{_auto1} \\tag{1}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "in a domain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "(x,y)\\in (0,L_x)\\times (0,L_y),\\ t\\in (0,T],\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with $u=0$ on the boundary and $u(x,y,0)=I(x,y)$ as initial condition.\n",
    "\n",
    "## Discretization\n",
    "<div id=\"diffu:2D:discr\"></div>\n",
    "\n",
    "\n",
    "For generality, it is natural to use a $\\theta$-rule for the time\n",
    "discretization. Standard, second-order accurate finite differences are\n",
    "used for the spatial derivatives. We sample the PDE at a space-time\n",
    "point $(i,j,n+\\frac{1}{2})$ and apply the difference approximations:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\lbrack D_t u\\rbrack^{n+\\frac{1}{2}} =\n",
    "\\theta \\lbrack \\dfc (D_xD_x u + D_yD_yu) + f\\rbrack^{n+1} + \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto2\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\\quad (1-\\theta)\\lbrack \\dfc (D_xD_x u + D_yD_y u) + f\\rbrack^{n}\\thinspace .\n",
    "\\label{_auto2} \\tag{2}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Written out,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\frac{u^{n+1}_{i,j}-u^n_{i,j}}{\\Delta t} =\\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\qquad \\theta (\\dfc\n",
    "(\\frac{u^{n+1}_{i-1,j} - 2u^{n+1}_{i,j} + u^{n+1}_{i+1,j}}{\\Delta x^2} +\n",
    "\\frac{u^{n+1}_{i,j-1} - 2u^{n+1}_{i,j} + u^{n+1}_{i,j+1}}{\\Delta y^2}) +\n",
    "f^{n+1}_{i,j})\n",
    "+ \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto3\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\\qquad (1-\\theta)(\\dfc\n",
    "(\\frac{u^{n}_{i-1,j} - 2u^{n}_{i,j} + u^{n}_{i+1,j}}{\\Delta x^2} +\n",
    "\\frac{u^{n}_{i,j-1} - 2u^{n}_{i,j} + u^{n}_{i,j+1}}{\\Delta y^2}) +\n",
    "f^{n}_{i,j})\n",
    "\\label{_auto3} \\tag{3}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We collect the unknowns on the left-hand side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "u^{n+1}_{i,j} -\n",
    "\\theta\\left(\n",
    "F_x\n",
    "(u^{n+1}_{i-1,j} - 2u^{n+1}_{i,j} + u^{n+1}_{i+1,j}) +\n",
    "F_y\n",
    "(u^{n+1}_{i,j-1} - 2u^{n+1}_{i,j} + u^{n+1}_{i,j+1})\\right)\n",
    "= \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\qquad\n",
    "(1-\\theta)\\left(\n",
    "F_x\n",
    "(u^{n}_{i-1,j} - 2u^{n}_{i,j} + u^{n}_{i+1,j}) +\n",
    "F_y\n",
    "(u^{n}_{i,j-1} - 2u^{n}_{i,j} + u^{n}_{i,j+1})\\right) + \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"diffu:2D:theta_scheme2\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\\qquad \\theta \\Delta t f^{n+1}_{i,j} + (1-\\theta) \\Delta t f^{n}_{i,j}\n",
    "+ u^n_{i,j},\n",
    "\\label{diffu:2D:theta_scheme2} \\tag{4}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "F_x = \\frac{\\dfc\\Delta t}{\\Delta x^2},\\quad F_y = \\frac{\\dfc\\Delta t}{\\Delta y^2},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "are the Fourier numbers in $x$ and $y$ direction, respectively.\n",
    "\n",
    "<!-- dom:FIGURE: [fig-diffu/mesh3x2.png, width=500 frac=0.7] 3x2 2D mesh. <div id=\"diffu:2D:fig:mesh3x2\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"diffu:2D:fig:mesh3x2\"></div>\n",
    "\n",
    "<p>3x2 2D mesh.</p>\n",
    "<img src=\"fig-diffu/mesh3x2.png\" width=500>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "## Numbering of mesh points versus equations and unknowns\n",
    "<div id=\"diffu:2D:numbering\"></div>\n",
    "\n",
    "<!-- Nx=3, Ny=2 -->\n",
    "The equations ([4](#diffu:2D:theta_scheme2)) are coupled at the new\n",
    "time level $n+1$. That is, we must solve a system of (linear) algebraic\n",
    "equations, which we will write as $Ac=b$, where $A$ is the coefficient\n",
    "matrix, $c$ is the vector of unknowns, and $b$ is the right-hand side.\n",
    "\n",
    "Let us examine the equations in $Ac=b$ on a mesh with $N_x=3$ and\n",
    "$N_y=2$ cells in the respective spatial directions.  The spatial mesh is depicted in\n",
    "[Figure](#diffu:2D:fig:mesh3x2).  The equations at the boundary just\n",
    "implement the boundary condition $u=0$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "& u^{n+1}_{0,0}=\n",
    "u^{n+1}_{1,0}=\n",
    "u^{n+1}_{2,0}=\n",
    "u^{n+1}_{3,0}=\n",
    "u^{n+1}_{0,1}=\\\\\n",
    "& u^{n+1}_{3,1}=\n",
    "u^{n+1}_{0,2}=\n",
    "u^{n+1}_{1,2}=\n",
    "u^{n+1}_{2,2}=\n",
    "u^{n+1}_{3,2}= 0\\thinspace .\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are left with two interior points, with $i=1$, $j=1$ and $i=2$, $j=1$.\n",
    "The corresponding equations are"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "& u^{n+1}_{i,j} -\n",
    "\\theta\\left(\n",
    "F_x\n",
    "(u^{n+1}_{i-1,j} - 2u^{n+1}_{i,j} + u^{n+1}_{i+1,j}) +\n",
    "F_y\n",
    "(u^{n+1}_{i,j-1} - 2u^{n+1}_{i,j} + u^{n+1}_{i,j+1})\\right)\n",
    "=  \\\\\n",
    "&\\qquad\n",
    "(1-\\theta)\\left(\n",
    "F_x\n",
    "(u^{n}_{i-1,j} - 2u^{n}_{i,j} + u^{n}_{i+1,j}) +\n",
    "F_y\n",
    "(u^{n}_{i,j-1} - 2u^{n}_{i,j} + u^{n}_{i,j+1})\\right) + \\\\\n",
    "&\\qquad \\theta \\Delta t f^{n+1}_{i,j} + (1-\\theta) \\Delta t f^{n}_{i,j}\n",
    "+ u^n_{i,j},\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are in total 12 unknowns $u^{n+1}_{i,j}$ for $i=0,1,2,3$ and\n",
    "$j=0,1,2$.  To solve the equations, we need to form a matrix system $Ac=b$.\n",
    "In that system, the solution vector $c$ can only have one index. Thus,\n",
    "we need a numbering of the unknowns with one\n",
    "index, not two as used in the mesh. We introduce a mapping $m(i,j)$\n",
    "from a mesh point with indices $(i,j)$ to the corresponding unknown\n",
    "$p$ in the equation system:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p = m(i,j) = j(N_x+1) + i\\thinspace .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When $i$ and $j$ run through their values, we see the following mapping\n",
    "to $p$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "&(0,0)\\rightarrow 0,\\\n",
    "(0,1)\\rightarrow 1,\\\n",
    "(0,2)\\rightarrow 2,\\\n",
    "(0,3)\\rightarrow 3,\\\\\n",
    "&(1,0)\\rightarrow 4,\\\n",
    "(1,1)\\rightarrow 5,\\\n",
    "(1,2)\\rightarrow 6,\\\n",
    "(1,3)\\rightarrow 7,\\\\\n",
    "&(2,0)\\rightarrow 8,\\\n",
    "(2,1)\\rightarrow 9,\\\n",
    "(2,2)\\rightarrow 10,\\\n",
    "(2,3)\\rightarrow 11\\thinspace .\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, we number the points along the $x$ axis, starting with $y=0$,\n",
    "and then progress one \"horizontal\" mesh line at a time.\n",
    "In [Figure](#diffu:2D:fig:mesh3x2) you can see that the $(i,j)$ and the\n",
    "corresponding single index ($p$) are listed for each mesh point.\n",
    "\n",
    "We could equally well have numbered the equations in other ways, e.g.,\n",
    "let the $j$ index be the fastest varying index:\n",
    "$p = m(i,j) = i(N_y+1) + j$.\n",
    "\n",
    "Let us form the coefficient matrix $A$, or more precisely, insert a\n",
    "matrix element (according Python's convention with zero as base\n",
    "index) for each of the nonzero elements in $A$ (the indices\n",
    "run through the values of $p$, i.e., $p=0,\\ldots,11$):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "{\\tiny\n",
    "\\left(\\begin{array}{cccccccccccc}\n",
    "(0,0) &   0   &   0   &   0   &   0   &   0   &   0   &   0   &   0   &   0   &   0    &   0    \\\\\n",
    "  0   & (1,1) &   0   &   0   &   0   &   0   &   0   &   0   &   0   &   0   &   0    &   0    \\\\\n",
    "  0   &   0   & (2,2) &   0   &   0   &   0   &   0   &   0   &   0   &   0   &   0    &   0    \\\\\n",
    "  0   &   0   &   0   & (3,3) &   0   &   0   &   0   &   0   &   0   &   0   &   0    &   0    \\\\\n",
    "  0   &   0   &   0   &   0   & (4,4) &   0   &   0   &   0   &   0   &   0   &   0    &   0    \\\\\n",
    "  0   & (5,1) &   0   &   0   & (5,4) & (5,5) & (5,6) &   0   &   0   & (5,9) &   0    &   0    \\\\\n",
    "  0   &   0   & (6,2) &   0   &   0   & (6,5) & (6,6) & (6,7) &   0   &   0   & (6,10) &   0    \\\\\n",
    "  0   &   0   &   0   &   0   &   0   &   0   &   0   & (7,7) &   0   &   0   &   0    &   0    \\\\\n",
    "  0   &   0   &   0   &   0   &   0   &   0   &   0   &   0   & (8,8) &   0   &   0    &   0    \\\\\n",
    "  0   &   0   &   0   &   0   &   0   &   0   &   0   &   0   &   0   & (9,9) &   0    &   0    \\\\\n",
    "   0   &    0   &    0   &    0   &    0   &    0   &    0   &    0   &    0   &    0   & (10,10) &    0    \\\\\n",
    "   0   &    0   &    0   &    0   &    0   &    0   &    0   &    0   &    0   &    0   &    0    & (11,11) \\\\\n",
    "\\end{array}\\right)\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here is a more compact visualization of the coefficient matrix where we\n",
    "insert dots for zeros and bullets for non-zero elements:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\footnotesize\n",
    "\\left(\\begin{array}{cccccccccccc}\n",
    "\\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\bullet & \\cdot & \\cdot & \\bullet & \\bullet & \\bullet & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\bullet & \\bullet & \\bullet & \\cdot & \\cdot & \\bullet & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet \\\\\n",
    "\\end{array}\\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is clearly seen that most of the elements are zero. This is a general\n",
    "feature of coefficient matrices arising from discretizing PDEs by\n",
    "finite difference methods. We say that the matrix is *sparse*.\n",
    "\n",
    "\n",
    "Let $A_{p,q}$ be the value of element $(p,q)$ in the coefficient matrix $A$,\n",
    "where $p$ and $q$ now correspond to the numbering of the unknowns in the\n",
    "equation system.\n",
    "We have $A_{p,q}=1$ for $p=q=0,1,2,3,4,7,8,9,10,11$, corresponding\n",
    "to all the known boundary values. Let $p$ be $m(i,j)$, i.e.,\n",
    "the single index corresponding to mesh point $(i,j)$. Then we have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto4\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "A_{m(i,j),m(i,j)} = A_{p,p} =\n",
    "1 +\n",
    "\\theta (F_x + F_y),\n",
    "\\label{_auto4} \\tag{5}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto5\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "A_{p, m(i-1,j)} = A_{p,p-1} = -\\theta F_x,\n",
    "\\label{_auto5} \\tag{6}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto6\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "A_{p, m(i+1,j)} = A_{p,p+1} = -\\theta F_x,\n",
    "\\label{_auto6} \\tag{7}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto7\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "A_{p, m(i,j-1)} = A_{p, p-(N_x+1)} = -\\theta F_y,\n",
    "\\label{_auto7} \\tag{8}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto8\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "A_{p, m(i,j+1)} = A_{p, p+(N_x+1)} = -\\theta F_y,\n",
    "\\label{_auto8} \\tag{9}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the equations associated with the two interior mesh points.\n",
    "At these interior points, the single index $p$ takes on the\n",
    "specific values $p=5,6$, corresponding to the\n",
    "values $(1,1)$ and $(1,2)$ of the pair $(i,j)$.\n",
    "\n",
    "The above values for $A_{p,q}$ can be inserted in the matrix:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "{\\tiny\n",
    "\\left(\\begin{array}{cccccccccccc}\n",
    "1 &   0   &   0   &   0   &   0   &   0   &   0   &   0   &   0   &   0   &   0    &   0    \\\\\n",
    "  0   & 1 &   0   &   0   &   0   &   0   &   0   &   0   &   0   &   0   &   0    &   0    \\\\\n",
    "  0   &   0   & 1 &   0   &   0   &   0   &   0   &   0   &   0   &   0   &   0    &   0    \\\\\n",
    "  0   &   0   &   0   & 1 &   0   &   0   &   0   &   0   &   0   &   0   &   0    &   0    \\\\\n",
    "  0   &   0   &   0   &   0   & 1 &   0   &   0   &   0   &   0   &   0   &   0    &   0    \\\\\n",
    "  0   & -\\theta F_y &   0   &   0   & -\\theta F_x & 1+2\\theta F_x & -\\theta F_x &   0   &   0   & -\\theta F_y &   0    &   0    \\\\\n",
    "  0   &   0   & -\\theta F_y &   0   &   0   & -\\theta F_x & 1+2\\theta F_x & -\\theta F_x &   0   &   0   & -\\theta F_y &   0    \\\\\n",
    "  0   &   0   &   0   &   0   &   0   &   0   &   0   & 1 &   0   &   0   &   0    &   0    \\\\\n",
    "  0   &   0   &   0   &   0   &   0   &   0   &   0   &   0   & 1 &   0   &   0    &   0    \\\\\n",
    "  0   &   0   &   0   &   0   &   0   &   0   &   0   &   0   &   0   & 1 &   0    &   0    \\\\\n",
    "   0   &    0   &    0   &    0   &    0   &    0   &    0   &    0   &    0   &    0   & 1 &    0    \\\\\n",
    "   0   &    0   &    0   &    0   &    0   &    0   &    0   &    0   &    0   &    0   &    0    & 1 \\\\\n",
    "\\end{array}\\right)\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The corresponding right-hand side vector in the equation system has\n",
    "the entries $b_p$, where $p$ numbers the equations. We have"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "b_0=b_1=b_2=b_3=b_4=b_7=b_8=b_9=b_{10}=b_{11}=0,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for the boundary values. For the equations associated with the\n",
    "interior points, we get for $p=5,6$, corresponding to $i=1,2$ and $j=1$:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "b_p &= u^{n}_{i,j} +\n",
    "(1-\\theta)\\left(\n",
    "F_x\n",
    "(u^{n}_{i-1,j} - 2u^{n}_{i,j} + u^{n}_{i+1,j}) +\n",
    "F_y\n",
    "(u^{n}_{i,j-1} - 2u^{n}_{i,j} + u^{n}_{i,j+1})\\right) + \\\\\n",
    "&\\qquad \\theta \\Delta t f^{n+1}_{i,j} + (1-\\theta) \\Delta t f^{n}_{i,j}\\thinspace .\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall that $p=m(i,j)=j(N_x+1)+j$ in this expression.\n",
    "\n",
    "We can, as an alternative, leave the boundary mesh points out of the\n",
    "matrix system. For a mesh with $N_x=3$ and $N_y=2$ there are only two\n",
    "internal mesh points whose unknowns will enter the matrix system.\n",
    "We must now number the unknowns at the interior points:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "p = (j-1)(N_x-1) + i,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for $i=1,\\ldots,N_x-1$, $j=1,\\ldots,N_y-1$.\n",
    "\n",
    "<!-- Nx=4, Ny=3 -->\n",
    "\n",
    "<!-- dom:FIGURE: [fig-diffu/mesh4x3.png, width=700 frac=1] 4x3 2D mesh. <div id=\"diffu:2D:fig:mesh4x3\"></div> -->\n",
    "<!-- begin figure -->\n",
    "<div id=\"diffu:2D:fig:mesh4x3\"></div>\n",
    "\n",
    "<p>4x3 2D mesh.</p>\n",
    "<img src=\"fig-diffu/mesh4x3.png\" width=700>\n",
    "\n",
    "<!-- end figure -->\n",
    "\n",
    "\n",
    "We can continue with illustrating a bit larger mesh, $N_x=4$ and $N_y=3$,\n",
    "see [Figure](#diffu:2D:fig:mesh4x3). The corresponding coefficient matrix\n",
    "with dots for zeros and bullets for non-zeroes looks as follows (values at boundary points are included in the equation system):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "{\\tiny\n",
    "\\left(\\begin{array}{cccccccccccccccccccc}\n",
    "\\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\bullet & \\bullet & \\bullet & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\bullet & \\bullet & \\bullet & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\bullet & \\bullet & \\bullet & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\bullet & \\bullet & \\bullet & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\bullet & \\bullet & \\bullet & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\bullet & \\bullet & \\bullet & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot \\\\\n",
    "\\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet \\\\\n",
    "\\end{array}\\right)\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**The coefficient matrix is banded.**\n",
    "\n",
    "Besides being sparse, we observe that the coefficient matrix is *banded*:\n",
    "it has five distinct bands. We have the diagonal $A_{i,i}$, the\n",
    "subdiagonal $A_{i-1,j}$, the superdiagonal $A_{i,i+1}$, a lower\n",
    "diagonal $A_{i,i-(Nx+1)}$, and an upper diagonal $A_{i,i+(Nx+1)}$.\n",
    "The other matrix entries are known to be zero. With $N_x+1=N_y+1=N$,\n",
    "only a fraction $5N^{-2}$ of the matrix entries are nonzero, so the\n",
    "matrix is clearly very sparse for relevant $N$ values.\n",
    "The more we can compute with the nonzeros only, the faster the solution\n",
    "methods will potentially be.\n",
    "\n",
    "\n",
    "\n",
    "## Algorithm for setting up the coefficient matrix\n",
    "<div id=\"diffu:2D:alg\"></div>\n",
    "\n",
    "We looked at a specific mesh in the previous section, formulated\n",
    "the equations, and saw what the corresponding coefficient matrix and\n",
    "right-hand side are. Now our aim is to set up a general algorithm, for any\n",
    "choice of $N_x$ and $N_y$, that produces the coefficient matrix and\n",
    "the right-hand side vector.\n",
    "We start with a zero matrix and vector, run through each mesh point,\n",
    "and fill in the values depending on whether the mesh point is an interior\n",
    "point or on the boundary.\n",
    "\n",
    " * for $i=0,\\ldots,N_x$\n",
    "\n",
    "  * for $j=0,\\ldots, N_y$\n",
    "\n",
    "    * $p=j(N_x+1)+i$\n",
    "\n",
    "    * if point $(i,j)$ is on the boundary:\n",
    "\n",
    "      * $A_{p,p}=1$, $b_p=0$\n",
    "\n",
    "\n",
    "    * else:\n",
    "\n",
    "      * fill $A_{p,m(i-1,j)}$, $A_{p,m(i+1,j)}$, $A_{p,m(i,j)}$, $A_{p,m(i,j-1)}$, $A_{p,m(i,j+1)}$, and $b_p$\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "To ease the test on whether $(i,j)$ is on the boundary or not, we can\n",
    "split the loops a bit, starting with the boundary line $j=0$, then\n",
    "treat the interior lines $1\\leq j<N_y$, and finally treat the boundary\n",
    "line $j=N_y$:\n",
    "\n",
    " * for $i=0,\\ldots,N_x$\n",
    "\n",
    "  * boundary $j=0$: $p=j(N_x+1)+i$, $A_{p,p}=1$\n",
    "\n",
    "\n",
    " * for $j=0,\\ldots,N_y$\n",
    "\n",
    "  * boundary $i=0$: $p=j(N_x+1)+i$, $A_{p,p}=1$\n",
    "\n",
    "  * for $i=1,\\ldots, N_x-1$\n",
    "\n",
    "    * interior point $p=j(N_x+1)+i$\n",
    "\n",
    "    * fill $A_{p,m(i-1,j)}$, $A_{p,m(i+1,j)}$, $A_{p,m(i,j)}$, $A_{p,m(i,j-1)}$, $A_{p,m(i,j+1)}$, and $b_p$\n",
    "\n",
    "\n",
    "  * boundary $i=N_x$: $p=j(N_x+1)+i$, $A_{p,p}=1$\n",
    "\n",
    "\n",
    " * for $i=0,\\ldots,N_x$\n",
    "\n",
    "  * boundary $j=N_y$: $p=j(N_x+1)+i$, $A_{p,p}=1$\n",
    "\n",
    "\n",
    "The right-hand side is set up as follows.\n",
    "\n",
    " * for $i=0,\\ldots,N_x$\n",
    "\n",
    "  * boundary $j=0$: $p=j(N_x+1)+i$, $b_p=0$\n",
    "\n",
    "\n",
    " * for $j=0,\\ldots,N_y$\n",
    "\n",
    "  * boundary $i=0$: $p=j(N_x+1)+i$, $b_p=0$\n",
    "\n",
    "  * for $i=1,\\ldots, N_x-1$\n",
    "\n",
    "    * interior point $p=j(N_x+1)+i$\n",
    "\n",
    "    * fill $b_p$\n",
    "\n",
    "\n",
    "  * boundary $i=N_x$: $p=j(N_x+1)+i$, $b_p=0$\n",
    "\n",
    "\n",
    " * for $i=0,\\ldots,N_x$\n",
    "\n",
    "  * boundary $j=N_y$: $p=j(N_x+1)+i$, $b_p=0$\n",
    "\n",
    "\n",
    "## Implementation with a dense coefficient matrix\n",
    "<div id=\"diffu:2D:impl:dense\"></div>\n",
    "\n",
    "The goal now is to map the algorithms in the previous section to\n",
    "Python code. One should, for computational efficiency reasons, take\n",
    "advantage of the fact that the coefficient matrix is sparse and/or\n",
    "banded, i.e., take advantage of all the zeros. However, we first demonstrate\n",
    "how to fill an $N\\times N$ dense square matrix, where $N$ is the number\n",
    "of unknowns, here $N=(N_x+1)(N_y+1)$. The dense matrix is much easier\n",
    "to understand than the sparse matrix case."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def solver_dense(\n",
    "    I, a, f, Lx, Ly, Nx, Ny, dt, T, theta=0.5, user_action=None):\n",
    "    \"\"\"\n",
    "    Solve u_t = a*(u_xx + u_yy) + f, u(x,y,0)=I(x,y), with u=0\n",
    "    on the boundary, on [0,Lx]x[0,Ly]x[0,T], with time step dt,\n",
    "    using the theta-scheme.\n",
    "    \"\"\"\n",
    "    x = np.linspace(0, Lx, Nx+1)       # mesh points in x dir\n",
    "    y = np.linspace(0, Ly, Ny+1)       # mesh points in y dir\n",
    "    dx = x[1] - x[0]\n",
    "    dy = y[1] - y[0]\n",
    "\n",
    "    dt = float(dt)                    # avoid integer division\n",
    "    Nt = int(round(T/float(dt)))\n",
    "    t = np.linspace(0, Nt*dt, Nt+1)   # mesh points in time\n",
    "\n",
    "    # Mesh Fourier numbers in each direction\n",
    "    Fx = a*dt/dx**2\n",
    "    Fy = a*dt/dy**2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The $u^{n+1}_{i,j}$ and $u^n_{i,j}$ mesh functions are represented\n",
    "by their spatial values at the mesh points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "u   = np.zeros((Nx+1, Ny+1))      # unknown u at new time level\n",
    "u_n = np.zeros((Nx+1, Ny+1))      # u at the previous time level"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is a good habit (for extensions) to\n",
    "introduce index sets for all mesh points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "Ix = range(0, Nx+1)\n",
    "Iy = range(0, Ny+1)\n",
    "It = range(0, Nt+1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The initial condition is easy to fill in:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Load initial condition into u_n\n",
    "for i in Ix:\n",
    "    for j in Iy:\n",
    "        u_n[i,j] = I(x[i], y[j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The memory for the coefficient matrix and right-hand side vector\n",
    "is allocated by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "N = (Nx+1)*(Ny+1)  # no of unknowns\n",
    "A = np.zeros((N, N))\n",
    "b = np.zeros(N)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The filling of `A` goes like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = lambda i, j: j*(Nx+1) + i\n",
    "\n",
    "# Equations corresponding to j=0, i=0,1,... (u known)\n",
    "j = 0\n",
    "for i in Ix:\n",
    "    p = m(i,j);  A[p, p] = 1\n",
    "\n",
    "# Loop over all internal mesh points in y diretion\n",
    "# and all mesh points in x direction\n",
    "for j in Iy[1:-1]:\n",
    "    i = 0;  p = m(i,j);  A[p, p] = 1   # Boundary\n",
    "    for i in Ix[1:-1]:                 # Interior points\n",
    "        p = m(i,j)\n",
    "        A[p, m(i,j-1)] = - theta*Fy\n",
    "        A[p, m(i-1,j)] = - theta*Fx\n",
    "        A[p, p]        = 1 + 2*theta*(Fx+Fy)\n",
    "        A[p, m(i+1,j)] = - theta*Fx\n",
    "        A[p, m(i,j+1)] = - theta*Fy\n",
    "    i = Nx;  p = m(i,j);  A[p, p] = 1  # Boundary\n",
    "# Equations corresponding to j=Ny, i=0,1,... (u known)\n",
    "j = Ny\n",
    "for i in Ix:\n",
    "    p = m(i,j);  A[p, p] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since `A` is independent of time, it can be filled once and for all before\n",
    "the time loop. The right-hand side vector must be filled at each\n",
    "time level inside the time loop:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.linalg\n",
    "\n",
    "for n in It[0:-1]:\n",
    "    # Compute b\n",
    "    j = 0\n",
    "    for i in Ix:\n",
    "        p = m(i,j);  b[p] = 0           # Boundary\n",
    "    for j in Iy[1:-1]:\n",
    "        i = 0;  p = m(i,j);  b[p] = 0   # Boundary\n",
    "        for i in Ix[1:-1]:              # Interior points\n",
    "            p = m(i,j)\n",
    "            b[p] = u_n[i,j] + \\\n",
    "              (1-theta)*(\n",
    "              Fx*(u_n[i+1,j] - 2*u_n[i,j] + u_n[i-1,j]) +\\\n",
    "              Fy*(u_n[i,j+1] - 2*u_n[i,j] + u_n[i,j-1]))\\\n",
    "                + theta*dt*f(i*dx,j*dy,(n+1)*dt) + \\\n",
    "              (1-theta)*dt*f(i*dx,j*dy,n*dt)\n",
    "        i = Nx;  p = m(i,j);  b[p] = 0  # Boundary\n",
    "    j = Ny\n",
    "    for i in Ix:\n",
    "        p = m(i,j);  b[p] = 0           # Boundary\n",
    "\n",
    "    # Solve matrix system A*c = b\n",
    "    c = scipy.linalg.solve(A, b)\n",
    "\n",
    "    # Fill u with vector c\n",
    "    for i in Ix:\n",
    "        for j in Iy:\n",
    "            u[i,j] = c[m(i,j)]\n",
    "\n",
    "    # Update u_n before next step\n",
    "    u_n, u = u, u_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use `solve` from `scipy.linalg` and not from `numpy.linalg`. The difference\n",
    "is stated below.\n",
    "\n",
    "\n",
    "**`scipy.linalg` versus `numpy.linalg`.**\n",
    "\n",
    "Quote from the [SciPy documentation](http://docs.scipy.org/doc/scipy/reference/tutorial/linalg.html):\n",
    "\n",
    "`scipy.linalg` contains all the functions in `numpy.linalg`\n",
    "plus some other more advanced ones not contained in `numpy.linalg`.\n",
    "\n",
    "Another advantage of using `scipy.linalg` over numpy.linalg is that it is always compiled with BLAS/LAPACK support, while for NumPy this is optional. Therefore, the SciPy version might be faster depending on how NumPy was installed.\n",
    "\n",
    "Therefore, unless you don't want to add SciPy as a dependency to your NumPy program, use `scipy.linalg` instead of `numpy.linalg`.\n",
    "\n",
    "\n",
    "\n",
    "The code shown above is available in the `solver_dense` function\n",
    "in the file [`diffu2D_u0.py`](${src_diffu}/diffu2D_u0.py), differing only\n",
    "in the boundary conditions, which in the code can be an arbitrary function along\n",
    "each side of the domain.\n",
    "\n",
    "We do not bother to look at vectorized versions of filling `A` since\n",
    "a dense matrix is just used of pedagogical reasons for the very first\n",
    "implementation. Vectorization will be treated when `A` has a sparse\n",
    "matrix representation, as in the section [Implementation with a sparse coefficient matrix](#diffu:2D:impl:sparse).\n",
    "\n",
    "\n",
    "**How to debug the computation of $A$ and $b$.**\n",
    "\n",
    "A good starting point for debugging the filling of $A$ and $b$ is\n",
    "to choose a very coarse mesh, say $N_x=N_y=2$, where there is just\n",
    "one internal mesh point, compute the equations by hand, and\n",
    "print out `A` and `b` for comparison in the code. If wrong elements\n",
    "in `A` or `b` occur, print out each assignment to elements in\n",
    "`A` and `b` inside the loops and compare with what you expect.\n",
    "\n",
    "\n",
    "\n",
    "To let the user store, analyze, or visualize the solution at each\n",
    "time level, we include a callback function, named `user_action`,\n",
    "to be called before the time loop and in each pass in that loop.\n",
    "The function has the signature"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "user_action(u, x, xv, y, yv, t, n)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where `u` is a two-dimensional array holding the solution at time level `n`\n",
    "and time `t[n]`. The $x$ and $y$ coordinates of the mesh points are given by\n",
    "the arrays `x` and `y`, respectively. The arrays `xv` and `yv` are\n",
    "vectorized representations of the mesh points such that vectorized\n",
    "function evaluations can be invoked. The `xv` and `yv` arrays are\n",
    "defined by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "xv = x[:,np.newaxis]\n",
    "yv = y[np.newaxis,:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can then evaluate, e.g., $f(x,y,t)$ at all internal mesh points at time\n",
    "level `n` by first evaluating $f$ at all points,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f_a = f(xv, yv, t[n])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and then use slices to extract a view of the values at the internal\n",
    "mesh points: `f_a[1:-1,1:-1]`.\n",
    "The next section features an example on writing a `user_action`\n",
    "callback function.\n",
    "\n",
    "\n",
    "## Verification: exact numerical solution\n",
    "<div id=\"diffu:2D:verify\"></div>\n",
    "\n",
    "A good test example to start with is one that preserves the solution\n",
    "$u=0$, i.e., $f=0$ and $I(x,y)=0$. This trivial solution can uncover\n",
    "some bugs.\n",
    "\n",
    "The first real test example is based on having an exact solution of\n",
    "the discrete equations. This solution is linear in time and quadratic\n",
    "in space:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "u(x,y,t) = 5tx(L_x-x)y(y-L_y)\\thinspace .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inserting this manufactured solution in the PDE shows that the\n",
    "source term $f$ must be"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f(x,y,t) = 5x(L_x-x)y(y-L_y) + 10\\dfc t (x(L_x-x)+ y(y-L_y))\\thinspace .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can use the `user_action` function to compare the numerical solution\n",
    "with the exact solution at each time level. A suitable helper function\n",
    "for checking the solution goes like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        def quadratic(theta, Nx, Ny):\n",
    "        \n",
    "            def u_exact(x, y, t):\n",
    "                return 5*t*x*(Lx-x)*y*(Ly-y)\n",
    "            def I(x, y):\n",
    "                return u_exact(x, y, 0)\n",
    "            def f(x, y, t):\n",
    "                return 5*x*(Lx-x)*y*(Ly-y) + 10*a*t*(y*(Ly-y)+x*(Lx-x))\n",
    "        \n",
    "            # Use rectangle to detect errors in switching i and j in scheme\n",
    "            Lx = 0.75\n",
    "            Ly = 1.5\n",
    "            a = 3.5\n",
    "            dt = 0.5\n",
    "            T = 2\n",
    "        \n",
    "            def assert_no_error(u, x, xv, y, yv, t, n):\n",
    "                \"\"\"Assert zero error at all mesh points.\"\"\"\n",
    "                u_e = u_exact(xv, yv, t[n])\n",
    "                diff = abs(u - u_e).max()\n",
    "                tol = 1E-12\n",
    "                msg = 'diff=%g, step %d, time=%g' % (diff, n, t[n])\n",
    "                print msg\n",
    "                assert diff < tol, msg\n",
    "        \n",
    "            solver_dense(\n",
    "                I, a, f, Lx, Ly, Nx, Ny,\n",
    "                dt, T, theta, user_action=assert_no_error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A true test function for checking the quadratic solution for several\n",
    "different meshes and $\\theta$ values can take the form"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def test_quadratic():\n",
    "    # For each of the three schemes (theta = 1, 0.5, 0), a series of\n",
    "    # meshes are tested (Nx > Ny and Nx < Ny)\n",
    "    for theta in [1, 0.5, 0]:\n",
    "        for Nx in range(2, 6, 2):\n",
    "            for Ny in range(2, 6, 2):\n",
    "                print 'testing for %dx%d mesh' % (Nx, Ny)\n",
    "                quadratic(theta, Nx, Ny)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Verification: convergence rates\n",
    "<div id=\"diffu:2D:convrate\"></div>\n",
    "\n",
    "For 2D verification with convergence rate computations, the expressions\n",
    "and computations just build naturally on what we saw for 1D diffusion.\n",
    "Truncation error analysis and other forms of error analysis point to a\n",
    "numerical error formula like"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "E = C_t\\Delta t^p + C_x\\Delta x^2 + C_y\\Delta y^2,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $p$, $C_t$, $C_x$, and $C_y$ are constants. Often, the analysis of\n",
    "a Crank-Nicolson\n",
    "method can show that $p=2$, while the Forward and Backward Euler schemes\n",
    "have $p=1$.\n",
    "\n",
    "When checking the error formula empirically, we need to reduce it to\n",
    "a form $E=Ch^r$ with a single discretization parameter $h$ and some\n",
    "rate $r$ to be estimated. For the Backward Euler method,\n",
    "where $p=1$, we can introduce a single discretization parameter\n",
    "according to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "h = \\Delta x^2 =  \\Delta y^2,\\quad h = K^{-1}\\Delta t,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $K$ is a constant. The error formula then becomes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "E = C_t Kh + C_xh + C_yh = \\tilde C h,\\quad \\tilde C = C_tK + C_x + C_y\\thinspace .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The simplest choice is obviously $K=1$. With the Forward Euler method, however,\n",
    "stability requires $\\Delta t = hK \\leq h/(4\\dfc)$, so $K\\leq 1/(4\\dfc)$.\n",
    "\n",
    "For the Crank-Nicolson method, $p=2$, and we can simply choose"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "h = \\Delta x = \\Delta y = \\Delta t,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "since there is no restriction on $\\Delta t$ in terms of $\\Delta x$ and\n",
    "$\\Delta y$.\n",
    "\n",
    "A frequently used error measure is the $\\ell^2$ norm of the error mesh\n",
    "point values. The section [wave:pde2:fd:MMS](#wave:pde2:fd:MMS) and the formula\n",
    "([wave:pde2:fd:MMS:E:l2](#wave:pde2:fd:MMS:E:l2)) shows the error measure for a 1D\n",
    "time-dependent problem. The extension to the current 2D problem\n",
    "reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "E = \\left(\\Delta t\\Delta x\\Delta y \\sum_{n=0}^{N_t}\n",
    "\\sum_{i=0}^{N_x}\\sum_{j=0}^{N_y}(\\uex(x_i,y_j,t_n)\n",
    "- u^n_{i,j})^2\\right)^{\\frac{1}{2}}\\thinspace .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One attractive manufactured solution is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\uex = e^{-pt}\\sin(k_xx)\\sin(k_yy),\\quad k_x=\\frac{\\pi}{L_x},\n",
    "k_y=\\frac{\\pi}{L_y},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $p$ can be arbitrary. The required source term is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "f = (\\dfc(k_x^2 + k_y^2) - p)\\uex\\thinspace .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `convergence_rates` in\n",
    "[`diffu2D_u0.py`](${src_diffu}/diffu2D_u0.py) implements a convergence\n",
    "rate test. Two potential difficulties are important to be aware of:\n",
    "\n",
    "1. The error formula is assumed to be\n",
    "   correct when $h\\rightarrow 0$, so for coarse meshes the estimated rate\n",
    "   $r$ may be somewhat away from the expected value.\n",
    "   Fine meshes may lead to prohibitively long execution times.\n",
    "\n",
    "2. Choosing $p=\\dfc (k_x^2 + k_y^2)$ in the manufactured solution above\n",
    "   seems attractive ($f=0$), but leads to a slower approach to the\n",
    "   asymptotic range where the error formula is valid (i.e., $r$\n",
    "   fluctuates and needs finer meshes to stabilize).\n",
    "\n",
    "## Implementation with a sparse coefficient matrix\n",
    "<div id=\"diffu:2D:impl:sparse\"></div>\n",
    "\n",
    "We used a sparse matrix implementation in the section [diffu:pde1:impl:sparse](#diffu:pde1:impl:sparse)\n",
    "for a 1D problem with a tridiagonal matrix. The present matrix, arising\n",
    "from a 2D problem, has five diagonals, but we can use the same\n",
    "sparse matrix data structure `scipy.sparse.diags`.\n",
    "\n",
    "### Understanding the diagonals\n",
    "\n",
    "Let us look closer at the diagonals in the example with a $4\\times 3$ mesh\n",
    "as depicted in [Figure](#diffu:2D:fig:mesh4x3) and its associated matrix\n",
    "visualized by dots for zeros and bullets for nonzeros. From the example\n",
    "mesh, we may generalize to an $N_x\\times N_y$ mesh."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "{\\tiny\n",
    "\\begin{array}{lcccccccccccccccccccc}\n",
    "0 =m(0,0) & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "1 = m(1,0) & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "2 = m(2,0) & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "3 = m(3,0) & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "N_x=m(N_x,0) & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "N_x+1=m(0,1) & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "(N_x+1)+1=m(1,1) & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\bullet & \\bullet & \\bullet & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "(N_x+1)+2=m(2,1) & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\bullet & \\bullet & \\bullet & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "(N_x+1)+3=m(3,1) & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\bullet & \\bullet & \\bullet & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "(N_x+1)+N_x=m(N_x,1) & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "2(N_x+1)=m(0,2)& \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "2(N_x+1)+1=m(1,2)& \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\bullet & \\bullet & \\bullet & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot \\\\\n",
    "2(N_x+1)+2=m(2,2)& \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\bullet & \\bullet & \\bullet & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot \\\\\n",
    "2(N_x+1)+3=m(3,2)& \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\bullet & \\bullet & \\bullet & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot \\\\\n",
    "2(N_x+1)+N_x=m(N_x,2)& \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "N_y(N_x+1)=m(0,N_y)& \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot & \\cdot \\\\\n",
    "N_y(N_x+1)+1=m(1,N_y)& \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot & \\cdot \\\\\n",
    "N_y(N_x+1)+2=m(2,N_y)& \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot & \\cdot \\\\\n",
    "N_y(N_x+1)+3=m(3,N_y)& \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet & \\cdot \\\\\n",
    "N_y(N_x+1)+N_x=m(N_x,N_y)& \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\cdot & \\bullet \\\\\n",
    "\\end{array}\n",
    "}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The main diagonal has $N=(N_x+1)(N_y+1)$ elements, while the sub- and\n",
    "super-diagonals have $N-1$ elements. By looking at the matrix above,\n",
    "we realize that the lower diagonal starts in row $N_x+1$ and goes to\n",
    "row $N$, so its length is $N-(N_x+1)$. Similarly, the upper diagonal\n",
    "starts at row 0 and lasts to row $N-(N_x+1)$, so it has the same length.\n",
    "Based on this information, we declare the diagonals by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "main   = np.zeros(N)            # diagonal\n",
    "lower  = np.zeros(N-1)          # subdiagonal\n",
    "upper  = np.zeros(N-1)          # superdiagonal\n",
    "lower2 = np.zeros(N-(Nx+1))     # lower diagonal\n",
    "upper2 = np.zeros(N-(Nx+1))     # upper diagonal\n",
    "b      = np.zeros(N)            # right-hand side"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling the diagonals\n",
    "\n",
    "We run through all mesh points and fill in elements on the various\n",
    "diagonals. The line of mesh points corresponding to $j=0$ are all\n",
    "on the boundary, and only the main diagonal gets a contribution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "m = lambda i, j: j*(Nx+1) + i\n",
    "j = 0; main[m(0,j):m(Nx+1,j)] = 1  # j=0 boundary line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then we run through all interior $j=\\hbox{const}$ lines of mesh points.\n",
    "The first and the last point on each line, $i=0$ and $i=N_x$, correspond\n",
    "to boundary points:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for j in Iy[1:-1]:             # Interior mesh lines j=1,...,Ny-1\n",
    "    i = 0;   main[m(i,j)] = 1\n",
    "    i = Nx;  main[m(i,j)] = 1  # Boundary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the interior mesh points $i=1,\\ldots,N_x-1$ on a mesh line $y=\\hbox{const}$\n",
    "we can start with the main diagonal. The entries to be filled go from\n",
    "$i=1$ to $i=N_x-1$ so the relevant slice in the `main` vector is\n",
    "`m(1,j):m(Nx,j)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "main[m(1,j):m(Nx,j)] = 1 + 2*theta*(Fx+Fy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `upper` array for the superdiagonal has its index 0 corresponding to\n",
    "row 0 in the matrix, and the array entries\n",
    "to be set go from $m(1,j)$ to $m(N_x-1,j)$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "upper[m(1,j):m(Nx,j)] = - theta*Fx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subdiagonal (`lower` array), however, has its index 0\n",
    "corresponding to row 1, so there is an offset of 1 in indices compared to\n",
    "the matrix. The first nonzero occurs (interior point) at a mesh line $j=\\hbox{const}$ corresponding to matrix row $m(1,j)$, and the corresponding array index\n",
    "in `lower` is then $m(1,j)$. To fill the entries from $m(1,j)$ to $m(N_x-1,j)$\n",
    "we set the following slice in `lower`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lower_offset = 1\n",
    "lower[m(1,j)-lower_offset:m(Nx,j)-lower_offset] = - theta*Fx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the upper diagonal, its index 0 corresponds to matrix row 0, so there\n",
    "is no offset and we can set the entries correspondingly to `upper`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "upper2[m(1,j):m(Nx,j)] = - theta*Fy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `lower2` diagonal, however, has its first index 0 corresponding to row\n",
    "$N_x+1$, so here we need to subtract the offset $N_x+1$:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lower2_offset = Nx+1\n",
    "lower2[m(1,j)-lower2_offset:m(Nx,j)-lower2_offset] = - theta*Fy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now summarize the above code lines for setting the entries in\n",
    "the sparse matrix representation of the coefficient matrix:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lower_offset = 1\n",
    "lower2_offset = Nx+1\n",
    "m = lambda i, j: j*(Nx+1) + i\n",
    "\n",
    "j = 0; main[m(0,j):m(Nx+1,j)] = 1  # j=0 boundary line\n",
    "for j in Iy[1:-1]:             # Interior mesh lines j=1,...,Ny-1\n",
    "    i = 0;   main[m(i,j)] = 1  # Boundary\n",
    "    i = Nx;  main[m(i,j)] = 1  # Boundary\n",
    "    # Interior i points: i=1,...,N_x-1\n",
    "    lower2[m(1,j)-lower2_offset:m(Nx,j)-lower2_offset] = - theta*Fy\n",
    "    lower[m(1,j)-lower_offset:m(Nx,j)-lower_offset] = - theta*Fx\n",
    "    main[m(1,j):m(Nx,j)] = 1 + 2*theta*(Fx+Fy)\n",
    "    upper[m(1,j):m(Nx,j)] = - theta*Fx\n",
    "    upper2[m(1,j):m(Nx,j)] = - theta*Fy\n",
    "j = Ny; main[m(0,j):m(Nx+1,j)] = 1  # Boundary line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The next task is to create the sparse matrix from these diagonals:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.sparse\n",
    "\n",
    "A = scipy.sparse.diags(\n",
    "    diagonals=[main, lower, upper, lower2, upper2],\n",
    "    offsets=[0, -lower_offset, lower_offset,\n",
    "             -lower2_offset, lower2_offset],\n",
    "    shape=(N, N), format='csr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling the right-hand side; scalar version\n",
    "\n",
    "Setting the entries in the right-hand side is easier, since there are no\n",
    "offsets in the array to take into account. The right-hand side is in fact similar to\n",
    "the one previously shown, when we used a dense matrix representation\n",
    "(the right-hand side vector is, of course, independent of what type of\n",
    "representation we use for the coefficient matrix). The complete time\n",
    "loop goes as follows."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import scipy.sparse.linalg\n",
    "\n",
    "for n in It[0:-1]:\n",
    "    # Compute b\n",
    "    j = 0\n",
    "    for i in Ix:\n",
    "        p = m(i,j);  b[p] = 0                     # Boundary\n",
    "    for j in Iy[1:-1]:\n",
    "        i = 0;  p = m(i,j);  b[p] = 0             # Boundary\n",
    "        for i in Ix[1:-1]:\n",
    "            p = m(i,j)                            # Interior\n",
    "            b[p] = u_n[i,j] + \\\n",
    "              (1-theta)*(\n",
    "              Fx*(u_n[i+1,j] - 2*u_n[i,j] + u_n[i-1,j]) +\\\n",
    "              Fy*(u_n[i,j+1] - 2*u_n[i,j] + u_n[i,j-1]))\\\n",
    "                + theta*dt*f(i*dx,j*dy,(n+1)*dt) + \\\n",
    "              (1-theta)*dt*f(i*dx,j*dy,n*dt)\n",
    "        i = Nx;  p = m(i,j);  b[p] = 0            # Boundary\n",
    "    j = Ny\n",
    "    for i in Ix:\n",
    "        p = m(i,j);  b[p] = 0                     # Boundary\n",
    "\n",
    "    # Solve matrix system A*c = b\n",
    "    c = scipy.sparse.linalg.spsolve(A, b)\n",
    "\n",
    "    # Fill u with vector c\n",
    "    for i in Ix:\n",
    "        for j in Iy:\n",
    "            u[i,j] = c[m(i,j)]\n",
    "\n",
    "    # Update u_n before next step\n",
    "    u_n, u = u, u_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling the right-hand side; vectorized version\n",
    "\n",
    "Since we use a sparse matrix and try to speed up the computations, we\n",
    "should examine the loops and see if some can be easily removed by\n",
    "vectorization. In the filling of $A$ we have already used vectorized\n",
    "expressions at each $j=\\hbox{const}$ line of mesh points. We can\n",
    "very easily do the same in the code above and remove the need for\n",
    "loops over the `i` index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n in It[0:-1]:\n",
    "    # Compute b, vectorized version\n",
    "\n",
    "    # Precompute f in array so we can make slices\n",
    "    f_a_np1 = f(xv, yv, t[n+1])\n",
    "    f_a_n   = f(xv, yv, t[n])\n",
    "\n",
    "    j = 0; b[m(0,j):m(Nx+1,j)] = 0     # Boundary\n",
    "    for j in Iy[1:-1]:\n",
    "        i = 0;   p = m(i,j);  b[p] = 0 # Boundary\n",
    "        i = Nx;  p = m(i,j);  b[p] = 0 # Boundary\n",
    "        imin = Ix[1]\n",
    "        imax = Ix[-1]  # for slice, max i index is Ix[-1]-1\n",
    "        b[m(imin,j):m(imax,j)] = u_n[imin:imax,j] + \\\n",
    "              (1-theta)*(Fx*(\n",
    "          u_n[imin+1:imax+1,j] -\n",
    "        2*u_n[imin:imax,j] + \\\n",
    "          u_n[imin-1:imax-1,j]) +\n",
    "                         Fy*(\n",
    "          u_n[imin:imax,j+1] -\n",
    "        2*u_n[imin:imax,j] +\n",
    "          u_n[imin:imax,j-1])) + \\\n",
    "            theta*dt*f_a_np1[imin:imax,j] + \\\n",
    "          (1-theta)*dt*f_a_n[imin:imax,j]\n",
    "    j = Ny;  b[m(0,j):m(Nx+1,j)] = 0 # Boundary\n",
    "\n",
    "    # Solve matrix system A*c = b\n",
    "    c = scipy.sparse.linalg.spsolve(A, b)\n",
    "\n",
    "    # Fill u with vector c\n",
    "    u[:,:] = c.reshape(Ny+1,Nx+1).T\n",
    "\n",
    "    # Update u_n before next step\n",
    "    u_n, u = u, u_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The most tricky part of this code snippet is the loading of values from\n",
    "the one-dimensional array `c`\n",
    "into the two-dimensional array `u`. With our numbering of unknowns\n",
    "from left to right along \"horizontal\" mesh lines, the correct\n",
    "reordering of the one-dimensional array `c` as a two-dimensional array\n",
    "requires first a reshaping to an `(Ny+1,Nx+1)` two-dimensional\n",
    "array and then taking the transpose. The result is an `(Nx+1,Ny+1)`\n",
    "array compatible with `u` both in size and appearance of the function values.\n",
    "\n",
    "The `spsolve` function in `scipy.sparse.linalg` is an efficient\n",
    "version of Gaussian elimination suited for matrices described by\n",
    "diagonals.  The algorithm is known as *sparse Gaussian elimination*,\n",
    "and `spsolve` calls up a well-tested C code called [SuperLU](http://crd-legacy.lbl.gov/~xiaoye/SuperLU/).\n",
    "\n",
    "The complete code utilizing `spsolve`\n",
    "is found in the `solver_sparse` function in the file\n",
    "[`diffu2D_u0.py`](${src_diffu}/diffu2D_u0.py).\n",
    "\n",
    "### Verification\n",
    "\n",
    "We can easily extend the function `quadratic` from\n",
    "the section [Verification: exact numerical solution](#diffu:2D:verify) to include a test of the\n",
    "`solver_sparse` function as well."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def quadratic(theta, Nx, Ny):\n",
    "    ...\n",
    "    t, cpu = solver_sparse(\n",
    "        I, a, f, Lx, Ly, Nx, Ny,\n",
    "        dt, T, theta, user_action=assert_no_error)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## The Jacobi iterative method\n",
    "\n",
    "\n",
    "So far we have created a matrix and right-hand side of a linear system\n",
    "$Ac=b$ and solved the system for $c$ by calling an exact algorithm\n",
    "based on Gaussian elimination. A much simpler implementation, which\n",
    "requires no memory for the coefficient matrix $A$, arises if we solve\n",
    "the system by *iterative* methods. These methods are only approximate,\n",
    "and the core algorithm is repeated many times until the solution is\n",
    "considered to be converged.\n",
    "\n",
    "### Numerical scheme and linear system\n",
    "\n",
    "To illustrate the idea of the Jacobi method, we simplify the numerical scheme to the\n",
    "Backward Euler case, $\\theta=1$, so there are fewer terms to write:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "u^{n+1}_{i,j} -\n",
    "\\left(\n",
    "F_x\n",
    "(u^{n+1}_{i-1,j} - 2u^{n+1}_{i,j} + u^{n+1}_{i+1,j}) +\n",
    "F_y\n",
    "(u^{n+1}_{i,j-1} - 2u^{n+1}_{i,j} + u^{n+1}_{i,j+1})\\right)\n",
    "= \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"diffu:2D:BE_scheme\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}  \\qquad u^n_{i,j} + \\Delta t f^{n+1}_{i,j}\n",
    "\\label{diffu:2D:BE_scheme} \\tag{10}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea of the *Jacobi* iterative method is to introduce an iteration,\n",
    "here with index $r$, where we in each iteration treat $u^{n+1}_{i,j}$\n",
    "as unknown, but use values from the previous iteration for\n",
    "the other unknowns $u^{n+1}_{i\\pm 1,j\\pm 1}$.\n",
    "\n",
    "### Iterations\n",
    "\n",
    "Let $u^{n+1,r}_{i,j}$\n",
    "be the approximation to $u^{n+1}_{i,j}$ in iteration $r$, for all\n",
    "relevant $i$ and $j$ indices. We first solve with respect to\n",
    "$u^{n+1}_{i,j}$ to get the equation to solve:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "u^{n+1}_{i,j} = (1+2F_x +2F_y)^{-1}\n",
    "\\left(\n",
    "F_x\n",
    "(u^{n+1}_{i-1,j} + u^{n+1}_{i+1,j}) +\n",
    "F_y\n",
    "(u^{n+1}_{i,j-1} + u^{n+1}_{i,j+1})\\right) +\n",
    "\\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"diffu:2D:Jacobi0\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}  \\qquad\n",
    "u^n_{i,j} + \\Delta t f^{n+1}_{i,j}\n",
    "\\label{diffu:2D:Jacobi0} \\tag{11}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The iteration is introduced by using iteration index $r$, for computed values,\n",
    "on the right-hand side and $r+1$ (unknown in this iteration) on the left-hand\n",
    "side:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "u^{n+1,r+1}_{i,j} = (1+2F_x +2F_y)^{-1}\\left(\n",
    "F_x\n",
    "(u^{n+1,r}_{i-1,j} + u^{n+1,r}_{i+1,j}) +\n",
    "F_y\n",
    "(u^{n+1,r}_{i,j-1} + u^{n+1,r}_{i,j+1})\\right)\n",
    "\\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"diffu:2D:Jacobi\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}  \\qquad\n",
    "+ u^n_{i,j} + \\Delta t f^{n+1}_{i,j}\n",
    "\\label{diffu:2D:Jacobi} \\tag{12}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Initial guess\n",
    "\n",
    "We start the iteration with the computed values at the previous time level:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"diffu:2D:iter:startvector\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "u^{n+1,0}_{i,j} = u^{n}_{i,j},\\quad i=0,\\ldots,N_x,\\ j=0,\\ldots,N_y\\thinspace .\n",
    "\\label{diffu:2D:iter:startvector} \\tag{13}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Relaxation\n",
    "\n",
    "A common technique in iterative methods is to introduce a *relaxation*,\n",
    "which means that the new approximation is a weighted mean of the\n",
    "approximation as suggested by the algorithm and the previous approximation.\n",
    "Naming the quantity on the left-hand side of ([12](#diffu:2D:Jacobi))\n",
    "as $u^{n+1,*}_{i,j}$, a new approximation based on relaxation reads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"diffu:2D:iter:relaxation\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "u^{n+1,r+1} = \\omega u^{n+1,*}_{i,j} + (1-\\omega) u^{n+1,r}_{i,j}\\thinspace .\n",
    "\\label{diffu:2D:iter:relaxation} \\tag{14}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Under-relaxation means $\\omega < 1$, while over-relaxation has\n",
    "$\\omega > 1$.\n",
    "\n",
    "### Stopping criteria\n",
    "\n",
    "The iteration can be stopped when the change from one iteration to the\n",
    "next is sufficiently small ($\\leq \\epsilon$), using either an infinity norm,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto9\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\max_{i,j}\\left\\vert u^{n+1,r+1}_{i,j}-u^{n+1,r}_{i,j}\n",
    "\\right\\vert \\leq \\epsilon,\n",
    "\\label{_auto9} \\tag{15}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "or an $L^2$ norm,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto10\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\left(\\Delta x\\Delta y\\sum_{i,j} (u^{n+1,r+1}_{i,j}-u^{n+1,r}_{i,j})^2\n",
    "\\right)^{\\frac{1}{2}} \\leq \\epsilon\\thinspace .\n",
    "\\label{_auto10} \\tag{16}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another widely used criterion measures how well the equations are solved\n",
    "by looking at the residual (essentially $b-Ac^{r+1}$ if $c^{r+1}$ is\n",
    "the approximation to the solution in iteration $r+1$).\n",
    "The residual, defined in terms of the finite difference stencil, is"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "R_{i,j} = u^{n+1,r+1}_{i,j} -\n",
    "(F_x(u^{n+1,r+1}_{i-1,j} - 2u^{n+1,r+1}_{i,j} + u^{n+1,r+1}_{i+1,j}) +\\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\quad\\quad F_y(u^{n+1,r+1}_{i,j-1} - 2u^{n+1,r+1}_{i,j} + u^{n+1,r+1}_{i,j+1}))\n",
    "- \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"diffu:2D:residual\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\\qquad u^n_{i,j} -  \\Delta t f^{n+1}_{i,j}\n",
    "\\label{diffu:2D:residual} \\tag{17}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One can then iterate until the norm of the mesh function $R_{i,j}$\n",
    "is less than some tolerance:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto11\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\left(\\Delta x\\Delta y\\sum_{i,j} R_{i,j}^2\n",
    "\\right)^{\\frac{1}{2}} \\leq \\epsilon\\thinspace .\n",
    "\\label{_auto11} \\tag{18}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code-friendly notation\n",
    "\n",
    "To make the mathematics as close as possible to what we will write in\n",
    "a computer program, we may introduce some new notation: $u_{i,j}$ is a\n",
    "short notation for $u^{n+1,r+1}_{i,j}$, $u^{-}_{i,j}$ is a short\n",
    "notation for $u^{n+1,r}_{i,j}$, and $u^{(s)}_{i,j}$ denotes\n",
    "$u^{n+1-s}_{i,j}$.  That is, $u_{i,j}$ is the unknown, $u^{-}_{i,j}$\n",
    "is its most recently computed approximation, and $s$ counts time\n",
    "levels backwards in time. The Jacobi method\n",
    "([12](#diffu:2D:Jacobi))) takes the following form with the new\n",
    "notation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "u^{*}_{i,j} = (1+2F_x +2F_y)^{-1}((\n",
    "F_x\n",
    "(u^{-}_{i-1,j} + u^{-}_{i+1,j}) +\n",
    "F_y\n",
    "(u^{-}_{i,j-1} + u^{-}_{i,j+1})) +\n",
    "\\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"diffu:2D:Jacobi2\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}  \\qquad\n",
    "u^{(1)}_{i,j} + \\Delta t f^{n+1}_{i,j})\n",
    "\\label{diffu:2D:Jacobi2} \\tag{19}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generalization of the scheme\n",
    "\n",
    "We can also quite easily introduce the $\\theta$ rule for discretization in\n",
    "time and write up the Jacobi iteration in that case as well:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "u^{*}_{i,j} = (1+ 2\\theta(F_x +F_y))^{-1}(\\theta(\n",
    "F_x\n",
    "(u^{-}_{i-1,j} + u^{-}_{i+1,j}) +\n",
    "F_y\n",
    "(u^{-}_{i,j-1} + u^{-}_{i,j+1})) +\n",
    "\\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\qquad\n",
    "u^{(1)}_{i,j} + \\theta \\Delta t f^{n+1}_{i,j}\n",
    "+ (1-\\theta)\\Delta t f^n_{i,j} + \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"diffu:2D:Jacobi3\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\\qquad (1-\\theta)(\n",
    "F_x(u^{(1)}_{i-1,j}-2u^{(1)}_{i,j} + u^{(1)}_{i+1,j}) +\n",
    "F_y(u^{(1)}_{i,j-1}-2u^{(1)}_{i,j} + u^{(1)}_{i,j+1})))\\thinspace .\n",
    "\\label{diffu:2D:Jacobi3} \\tag{20}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The final update of $u$ applies relaxation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "u_{i,j} = \\omega u^{*}_{i,j} + (1-\\omega)u^{-}_{i,j}\\thinspace .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementation of the Jacobi method\n",
    "<div id=\"diffu:2D:Jacobi:impl\"></div>\n",
    "\n",
    "The Jacobi method needs no coefficient matrix and right-hand side\n",
    "vector, but it needs an array for $u$ in the previous iteration.  We\n",
    "call this array `u_`, using the notation at the end of the previous\n",
    "section (at the same time level). The unknown itself is called `u`,\n",
    "while `u_n` is the computed solution one time level back in time.\n",
    "With a $\\theta$ rule in time, the time loop can be coded like this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n in It[0:-1]:\n",
    "    # Solve linear system by Jacobi iteration at time level n+1\n",
    "    u_[:,:] = u_n  # Start value\n",
    "    converged = False\n",
    "    r = 0\n",
    "    while not converged:\n",
    "        if version == 'scalar':\n",
    "            j = 0\n",
    "            for i in Ix:\n",
    "                u[i,j] = U_0y(t[n+1])           # Boundary\n",
    "            for j in Iy[1:-1]:\n",
    "                i = 0;   u[i,j] = U_0x(t[n+1])  # Boundary\n",
    "                i = Nx;  u[i,j] = U_Lx(t[n+1])  # Boundary\n",
    "\t\t# Interior points\n",
    "                for i in Ix[1:-1]:\n",
    "                    u_new = 1.0/(1.0 + 2*theta*(Fx + Fy))*(theta*(\n",
    "                        Fx*(u_[i+1,j] + u_[i-1,j]) +\n",
    "                        Fy*(u_[i,j+1] + u_[i,j-1])) + \\\n",
    "                    u_n[i,j] + \\\n",
    "                    (1-theta)*(Fx*(\n",
    "                    u_n[i+1,j] - 2*u_n[i,j] + u_n[i-1,j]) +\n",
    "                      Fy*(\n",
    "                    u_n[i,j+1] - 2*u_n[i,j] + u_n[i,j-1]))\\\n",
    "                      + theta*dt*f(i*dx,j*dy,(n+1)*dt) + \\\n",
    "                    (1-theta)*dt*f(i*dx,j*dy,n*dt))\n",
    "                    u[i,j] = omega*u_new + (1-omega)*u_[i,j]\n",
    "            j = Ny\n",
    "            for i in Ix:\n",
    "                u[i,j] = U_Ly(t[n+1])      # Boundary\n",
    "\n",
    "        elif version == 'vectorized':\n",
    "            j = 0;  u[:,j] = U_0y(t[n+1])  # Boundary\n",
    "            i = 0;  u[i,:] = U_0x(t[n+1])  # Boundary\n",
    "            i = Nx; u[i,:] = U_Lx(t[n+1])  # Boundary\n",
    "            j = Ny; u[:,j] = U_Ly(t[n+1])  # Boundary\n",
    "\t    # Internal points\n",
    "            f_a_np1 = f(xv, yv, t[n+1])\n",
    "            f_a_n   = f(xv, yv, t[n])\n",
    "            u_new = 1.0/(1.0 + 2*theta*(Fx + Fy))*(theta*(Fx*(\n",
    "              u_[2:,1:-1] + u_[:-2,1:-1]) +\n",
    "                Fy*(\n",
    "              u_[1:-1,2:] + u_[1:-1,:-2])) +\\\n",
    "            u_n[1:-1,1:-1] + \\\n",
    "              (1-theta)*(Fx*(\n",
    "              u_n[2:,1:-1] - 2*u_n[1:-1,1:-1] + u_n[:-2,1:-1]) +\\\n",
    "                Fy*(\n",
    "              u_n[1:-1,2:] - 2*u_n[1:-1,1:-1] + u_n[1:-1,:-2]))\\\n",
    "              + theta*dt*f_a_np1[1:-1,1:-1] + \\\n",
    "              (1-theta)*dt*f_a_n[1:-1,1:-1])\n",
    "            u[1:-1,1:-1] = omega*u_new + (1-omega)*u_[1:-1,1:-1]\n",
    "        r += 1\n",
    "        converged = np.abs(u-u_).max() < tol or r >= max_iter\n",
    "        u_[:,:] = u\n",
    "\n",
    "    # Update u_n before next step\n",
    "    u_n, u = u, u_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vectorized version should be quite straightforward to understand\n",
    "once one has an understanding of how a standard 2D finite stencil\n",
    "is vectorized.\n",
    "\n",
    "The first natural verification is to use the test problem\n",
    "in the function `quadratic` from\n",
    "the section [Verification: exact numerical solution](#diffu:2D:verify). This problem is known to have no\n",
    "approximation error, but any iterative method will produce an\n",
    "approximate solution with unknown error. For a tolerance $10^{-k}$\n",
    "in the iterative method, we can, e.g., use a slightly larger\n",
    "tolerance $10^{-(k-1)}$\n",
    "for the difference between the exact and the computed solution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def quadratic(theta, Nx, Ny):\n",
    "    ...\n",
    "    def assert_small_error(u, x, xv, y, yv, t, n):\n",
    "        \"\"\"Assert small error for iterative methods.\"\"\"\n",
    "        u_e = u_exact(xv, yv, t[n])\n",
    "        diff = abs(u - u_e).max()\n",
    "        tol = 1E-4\n",
    "        msg = 'diff=%g, step %d, time=%g' % (diff, n, t[n])\n",
    "        assert diff < tol, msg\n",
    "\n",
    "    for version in 'scalar', 'vectorized':\n",
    "        for theta in 1, 0.5:\n",
    "            print 'testing Jacobi, %s version, theta=%g' % \\\n",
    "                  (version, theta)\n",
    "            t, cpu = solver_Jacobi(\n",
    "                I=I, a=a, f=f, Lx=Lx, Ly=Ly, Nx=Nx, Ny=Ny,\n",
    "                dt=dt, T=T, theta=theta,\n",
    "                U_0x=0, U_0y=0, U_Lx=0, U_Ly=0,\n",
    "                user_action=assert_small_error,\n",
    "                version=version, iteration='Jacobi',\n",
    "                omega=1.0, max_iter=100, tol=1E-5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even for a very coarse $4\\times 4$ mesh, the Jacobi method requires\n",
    "26 iterations to reach a tolerance of $10^{-5}$,\n",
    "which is quite many iterations, given that there are only 25 unknowns.\n",
    "\n",
    "## Test problem: diffusion of a sine hill\n",
    "<div id=\"diffu:2D:Jacobi:impl:hill\"></div>\n",
    "\n",
    "It can be shown that"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"diffu:2D:Jacobi:impl:hill:uex\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\uex = Ae^{-\\dfc\\pi^2(L_x^{-2} + L_y^{-2})t}\n",
    "\\sin\\left(\\frac{\\pi}{L_x}x\\right)\\sin\\left(\\frac{\\pi}{L_y}y\\right),\n",
    "\\label{diffu:2D:Jacobi:impl:hill:uex} \\tag{21}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "is a solution of the 2D homogeneous diffusion equation\n",
    "$u_t = \\dfc(u_{xx}+u_{yy})$ in\n",
    "a rectangle $[0,L_x]\\times [0,L_y]$, for any value of the amplitude $A$.\n",
    "This solution vanishes at the boundaries,\n",
    "and the initial condition is the product of two sines.\n",
    "We may choose $A=1$ for simplicity.\n",
    "\n",
    "It is difficult to know if our solver based on the Jacobi method works\n",
    "properly since we are faced with two sources of errors: one from the\n",
    "discretization, $E_\\Delta$, and one from the iterative Jacobi method,\n",
    "$E_i$. The total error in the computed $u$ can be represented as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "E_u = E_\\Delta + E_i\\thinspace .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One error measure is to look at the maximum value, which is obtained for\n",
    "the midpoint $x=L_x/2$ and $y=L_x/2$. This midpoint is represented in\n",
    "the discrete `u` if $N_x$ and $N_y$ are even numbers. We can then\n",
    "compute $E_u$ as $E_u = |\\max \\uex - \\max u|$, when we know an exact\n",
    "solution $\\uex$ of the problem.\n",
    "\n",
    "What about $E_\\Delta$? If we use the maximum value as a measure of the\n",
    "error, we have in fact analytical insight into the approximation error\n",
    "in this particular problem. According to the section [diffu:2D:analysis](#diffu:2D:analysis), the exact solution\n",
    "([21](#diffu:2D:Jacobi:impl:hill:uex)) of the PDE problem is also an\n",
    "exact solution of the discrete equations, except that the damping\n",
    "factor in time is different. More precisely,\n",
    "([diffu:2D:analysis:BN:numexact](#diffu:2D:analysis:BN:numexact)) and\n",
    "([diffu:2D:analysis:CN:numexact](#diffu:2D:analysis:CN:numexact)) are solutions of the discrete\n",
    "problem for $\\theta=1$ (Backward Euler) and $\\theta=\\frac{1}{2}$\n",
    "(Crank-Nicolson), respectively.  The factors raised to the power $n$\n",
    "is the numerical amplitude, and the errors in these factors become"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\begin{align*}\n",
    "E_\\Delta &= e^{-\\dfc k^2t} - \\left(\n",
    "\\frac{1 - 2(F_x\\sin^2 p_x + F_x\\sin^2p_y)}{1 + 2(F_x\\sin^2 p_x + F_x\\sin^2p_y)}\n",
    "\\right)^n,\\quad \\theta=\\frac{1}{2},\\\\\n",
    "E_\\Delta &= e^{-\\dfc k^2t} -\n",
    "(1 + 4F_x\\sin^2 p_x + 4F_y\\sin^2 p_y)^{-n},\\quad\\theta=1\\thinspace .\n",
    "\\end{align*}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now in a position to compute $E_i$ numerically. That is, we can\n",
    "compute the error due to iterative solution of the linear system and\n",
    "see if it corresponds to the convergence tolerance used in the method.\n",
    "Note that the convergence is based on measuring the difference in\n",
    "two consecutive approximations, which is not exactly the error\n",
    "due to the iteration, but it is a kind of measure, and it should\n",
    "have about the same size as $E_i$.\n",
    "\n",
    "The function `demo_classic_iterative` in [`diffu2D_u0.py`](${src_diffu}/diffu2D_u0.py) implements the idea above (also for the\n",
    "methods in the section [The Gauss-Seidel and SOR methods](#diffu:2D:SOR)). The value of $E_i$ is in\n",
    "particular printed at each time level. By changing the tolerance in\n",
    "the convergence criterion of the Jacobi method, we can see that $E_i$\n",
    "is of the same order of magnitude as the prescribed tolerance in the\n",
    "Jacobi method.  For example: $E_\\Delta\\sim 10^{-2}$ with $N_x=N_y=10$\n",
    "and $\\theta=\\frac{1}{2}$, as long as $\\max u$ has some significant size\n",
    "($\\max u > 0.02$). An appropriate value of the tolerance is then\n",
    "$10^{-3}$, such that the error in the Jacobi method does not become\n",
    "bigger than the discretization error. In that case, $E_i$ is around\n",
    "$5\\cdot 10^{-3}$.  The corresponding number of Jacobi iterations (with\n",
    "$\\omega=1$) varies from 31 to 12 during the time simulation (for $\\max\n",
    "u > 0.02$). Changing the tolerance to $10^{-5}$ causes many more\n",
    "iterations (61 to 42) without giving any contribution to the overall\n",
    "accuracy, because the total error is dominated by $E_\\Delta$.\n",
    "\n",
    "Also, with an $N_x=N_y=20$, the spatial accuracy increases and many\n",
    "more iterations are needed (143 to 45), but the dominating error is\n",
    "from the time discretization. However, with such a finer spatial mesh,\n",
    "a higher tolerance in the convergence criterion $10^{-4}$ is needed to\n",
    "keep $E_i\\sim 10^{-3}$.  More experiments show the disadvantage of the\n",
    "very simple Jacobi iteration method: the number of iterations\n",
    "increases with the number of unknowns, keeping the tolerance fixed,\n",
    "but the tolerance should also be lowered to avoid the iteration error\n",
    "to dominate the total error. A small adjustment of the Jacobi method,\n",
    "as described in the section [The Gauss-Seidel and SOR methods](#diffu:2D:SOR), provides a better method.\n",
    "\n",
    "## The relaxed Jacobi method and its relation to the Forward Euler method\n",
    "<div id=\"diffu:2D:Jacobi_vs_FE\"></div>\n",
    "\n",
    "We shall now show that solving the Poisson equation $-\\dfc\\nabla^2 u =\n",
    "f$ by the Jacobi iterative method is in fact equivalent to using a\n",
    "Forward Euler scheme on $u_t = \\dfc\\nabla^2 u + f$ and letting\n",
    "$t\\rightarrow\\infty$.\n",
    "\n",
    "A Forward Euler discretization of the 2D diffusion equation,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\lbrack D_t^+ u = \\dfc (D_xD_x u + D_yD_y u) + f\\rbrack^n_{i,j},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "can be written out as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "u_{i,j}^{n+1} = u_{i,j}^n + \\frac{\\Delta t}{\\dfc h^2}\n",
    "\\left( u_{i-1,j}^n + u_{i+1,j}^n + u_{i,j-1}^n + u_{i,j+1}^n - 4u_{i,j}^n\n",
    "+ h^2f_{i,j}\\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $h=\\Delta x = \\Delta y$ has been introduced for simplicity. The\n",
    "scheme can be reordered as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "u_{i,j}^{n+1} = \\left(1 - \\omega\\right) u_{i,j}^n\n",
    "+ \\frac{1}{4}\\omega\n",
    "\\left( u_{i-1,j}^n + u_{i+1,j}^n + u_{i,j-1}^n + u_{i,j+1}^n - 4u_{i,j}^n\n",
    "+ h^2f_{i,j}\\right),\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\omega = 4\\frac{\\Delta t}{\\dfc h^2},\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "but this latter form is nothing but the relaxed Jacobi method applied to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "[D_xD_x u + D_yD_y u = -f]^n_{i,j}\\thinspace .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From the equivalence above we know a couple of things about the Jacobi\n",
    "method for solving $-\\nabla^2 u = f$:\n",
    "\n",
    "1. The method is unstable if $\\omega > 1$ (since the Forward Euler method\n",
    "   is then unstable).\n",
    "\n",
    "2. The convergence is really slow as the iteration index increases (coming from the fact that\n",
    "   the Forward Euler scheme requires many small time steps to reach the stationary solution).\n",
    "\n",
    "These observations are quite disappointing: if we already have a\n",
    "time-dependent diffusion problem and want to take larger time steps by\n",
    "an implicit time discretization method, we will with the Jacobi method\n",
    "end up with something close to a slow Forward Euler simulation of the\n",
    "original problem at each time level.  Nevertheless, the are two\n",
    "reasons for why the Jacobi method remains a fundamental building block\n",
    "for solving linear systems arising from PDEs: 1) a couple of\n",
    "iterations remove large parts of the error and this is effectively\n",
    "used in the very efficient class of multigrid methods; and 2) the idea\n",
    "of the Jacobi method can be developed into more efficient methods,\n",
    "especially the SOR method, which is treated next.\n",
    "\n",
    "## The Gauss-Seidel and SOR methods\n",
    "<div id=\"diffu:2D:SOR\"></div>\n",
    "\n",
    "\n",
    "If we update the mesh points according to the Jacobi method\n",
    "([11](#diffu:2D:Jacobi0)) for a Backward Euler discretization with a\n",
    "loop over $i=1,\\ldots,N_x-1$ and $j=1,\\ldots,N_y-1$, we realize that\n",
    "when $u^{n+1,r+1}_{i,j}$ is computed, $u^{n+1,r+1}_{i-1,j}$ and\n",
    "$u^{n+1,r+1}_{i,j-1}$ are already computed, so these new values can be\n",
    "used rather than $u^{n+1,r}_{i-1,j}$ and $u^{n+1,r}_{i,j-1}$\n",
    "(respectively) in the formula for $u^{n+1,r+1}_{i,j}$.  This idea\n",
    "gives rise to the *Gauss-Seidel* iteration method, which\n",
    "mathematically is just a small adjustment of ([11](#diffu:2D:Jacobi0)):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "u^{n+1,r+1}_{i,j} = (1+2F_x +2F_y)^{-1}((\\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"diffu:2D:SOR:eq\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}  \\qquad\n",
    "F_x\n",
    "(u^{n+1,r+1}_{i-1,j} + u^{n+1,r}_{i+1,j}) +\n",
    "F_y\n",
    "(u^{n+1,r+1}_{i,j-1} + u^{n+1,r}_{i,j+1})) +\n",
    "u^n_{i,j} + \\Delta t f^{n+1}_{i,j})\\thinspace .\n",
    "\\label{diffu:2D:SOR:eq} \\tag{22}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Observe that the way we access the mesh points in the formula\n",
    "([22](#diffu:2D:SOR:eq)) is important: points with $i-1$ must be\n",
    "computed before points with $i$, and points with $j-1$ must be\n",
    "computed before points with $j$. Any sequence of mesh points can be\n",
    "used in the Gauss-Seidel method, but the particular math formula must\n",
    "distinguish between already visited points in the current iteration\n",
    "and the points not yet visited.\n",
    "\n",
    "\n",
    "The idea of relaxation ([14](#diffu:2D:iter:relaxation)) can equally\n",
    "well be applied to the Gauss-Seidel method. Actually, the Gauss-Seidel\n",
    "method with an arbitrary $0<\\omega\\leq 2$ has its own name: the\n",
    "*Successive Over-Relaxation* method, abbreviated as SOR.\n",
    "\n",
    "The SOR method for a $\\theta$ rule discretization, with the\n",
    "shortened $u$ and $u^{-}$ notation, can be written"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "u^{*}_{i,j} = (1+ 2\\theta(F_x +F_y))^{-1}(\\theta(\n",
    "F_x\n",
    "(u_{i-1,j} + u^{-}_{i+1,j}) +\n",
    "F_y\n",
    "(u_{i,j-1} + u^{-}_{i,j+1})) +\n",
    "\\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "\\qquad\n",
    "u^{(1)}_{i,j} + \\theta \\Delta t f^{n+1}_{i,j}\n",
    "+ (1-\\theta)\\Delta t f^n_{i,j} + \\nonumber\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"diffu:2D:SOR3\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "\\qquad (1-\\theta)(\n",
    "F_x(u^{(1)}_{i-1,j}-2u^{(1)}_{i,j} + u^{(1)}_{i+1,j}) +\n",
    "F_y(u^{(1)}_{i,j-1}-2u^{(1)}_{i,j} + u^{(1)}_{i,j+1}))),\n",
    "\\label{diffu:2D:SOR3} \\tag{23}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto12\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation} \n",
    "u_{i,j} = \\omega u^{*}_{i,j} + (1-\\omega)u^{-}_{i,j}\n",
    "\\label{_auto12} \\tag{24}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The sequence of mesh points in ([23](#diffu:2D:SOR3)) is\n",
    "$i=1,\\ldots,N_x-1$, $j=1,\\ldots,N_y-1$ (but whether $i$ runs faster\n",
    "or slower than $j$ does not matter).\n",
    "\n",
    "\n",
    "## Scalar implementation of the SOR method\n",
    "<div id=\"diffu:2D:SOR:impl:scalar\"></div>\n",
    "\n",
    "Since the Jacobi and Gauss-Seidel methods with relaxation\n",
    "are so similar, we can easily make a common code for the two:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for n in It[0:-1]:\n",
    "    # Solve linear system by Jacobi/SOR iteration at time level n+1\n",
    "    u_[:,:] = u_n  # Start value\n",
    "    converged = False\n",
    "    r = 0\n",
    "    while not converged:\n",
    "        if version == 'scalar':\n",
    "            if iteration == 'Jacobi':\n",
    "                u__ = u_\n",
    "            elif iteration == 'SOR':\n",
    "                u__ = u\n",
    "            j = 0\n",
    "            for i in Ix:\n",
    "                u[i,j] = U_0y(t[n+1])  # Boundary\n",
    "            for j in Iy[1:-1]:\n",
    "                i = 0;   u[i,j] = U_0x(t[n+1])  # Boundary\n",
    "                i = Nx;  u[i,j] = U_Lx(t[n+1])  # Boundary\n",
    "                for i in Ix[1:-1]:\n",
    "                    u_new = 1.0/(1.0 + 2*theta*(Fx + Fy))*(theta*(\n",
    "                        Fx*(u_[i+1,j] + u__[i-1,j]) +\n",
    "                        Fy*(u_[i,j+1] + u__[i,j-1])) + \\\n",
    "                    u_n[i,j] + (1-theta)*(\n",
    "                      Fx*(\n",
    "                    u_n[i+1,j] - 2*u_n[i,j] + u_n[i-1,j]) +\n",
    "                      Fy*(\n",
    "                    u_n[i,j+1] - 2*u_n[i,j] + u_n[i,j-1]))\\\n",
    "                      + theta*dt*f(i*dx,j*dy,(n+1)*dt) + \\\n",
    "                    (1-theta)*dt*f(i*dx,j*dy,n*dt))\n",
    "                    u[i,j] = omega*u_new + (1-omega)*u_[i,j]\n",
    "                j = Ny\n",
    "                for i in Ix:\n",
    "                    u[i,j] = U_Ly(t[n+1])  # boundary\n",
    "        r += 1\n",
    "        converged = np.abs(u-u_).max() < tol or r >= max_iter\n",
    "        u_[:,:] = u\n",
    "\n",
    "    u_n, u = u, u_n  # Get ready for next iteration"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea here is to introduce `u__` to be used for already computed\n",
    "values (`u`) in the Gauss-Seidel/SOR version of the implementation, or\n",
    "just values from the previous iteration (`u_`) in case of the Jacobi method.\n",
    "\n",
    "## Vectorized implementation of the SOR method\n",
    "<div id=\"diffu:2D:SOR:impl:vectorized\"></div>\n",
    "\n",
    "Vectorizing the Gauss-Seidel iteration step turns out to be non-trivial.\n",
    "The problem is that vectorized operations typically imply\n",
    "operations on arrays where the sequence in which we visit the elements does\n",
    "not matter. In particular, this principle makes vectorized code trivial to\n",
    "parallelize. However, in the Gauss-Seidel algorithm, the sequence in which we\n",
    "visit the elements in the arrays does matter, and it is well known that\n",
    "the basic method as explained above cannot be parallelized.\n",
    "Therefore, also vectorization will require new thinking.\n",
    "\n",
    "\n",
    "The strategy for vectorizing (and parallelizing) the Gauss-Seidel\n",
    "method is to use a special numbering of the mesh points called\n",
    "red-black numbering: every other point is red or black as in a\n",
    "checkerboard pattern. This numbering requires $N_x$ and $N_y$ to\n",
    "be even numbers.\n",
    "Here is an example of a $6\\times 6$ mesh:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        r b r b r b r\n",
    "        b r b r b r b\n",
    "        r b r b r b r\n",
    "        b r b r b r b\n",
    "        r b r b r b r\n",
    "        b r b r b r b\n",
    "        r b r b r b r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The idea now is to first update all the red points. Each formula for\n",
    "updating a red point involves only the black neighbors. Thereafter, we\n",
    "update all the black points, and at each black point, only the\n",
    "recently computed red points are involved.\n",
    "\n",
    "The scalar implementation of the red-black numbered Gauss-Seidel\n",
    "method is really compact, since we can update values directly in\n",
    "`u` (this guarantees that we use the most recently computed\n",
    "values). Here is the relevant code for the Backward Euler\n",
    "scheme in time and without a source term:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Update internal points\n",
    "for sweep in 'red', 'black':\n",
    "    for j in range(1, Ny, 1):\n",
    "        if sweep == 'red':\n",
    "            start = 1 if j % 2 == 1 else 2\n",
    "        elif sweep == 'black':\n",
    "            start = 2 if j % 2 == 1 else 1\n",
    "        for i in range(start, Nx, 2):\n",
    "\t    u[i,j] = 1.0/(1.0 + 2*(Fx + Fy))*(\n",
    "                     Fx*(u[i+1,j] + u[i-1,j]) +\n",
    "                     Fy*(u[i,j+1] + u[i,j-1]) + u_n[i,j])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The vectorized version must be based on slices. Looking at a typical\n",
    "red-black pattern, e.g.,"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        r b r b r b r\n",
    "        b r b r b r b\n",
    "        r b r b r b r\n",
    "        b r b r b r b\n",
    "        r b r b r b r\n",
    "        b r b r b r b\n",
    "        r b r b r b r\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "we want to update the internal points (marking boundary points with\n",
    "`x`):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        x x x x x x x\n",
    "        x r b r b r x\n",
    "        x b r b r b x\n",
    "        x r b r b r x\n",
    "        x b r b r b x\n",
    "        x r b r b r x\n",
    "        x x x x x x x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is impossible to make one slice that picks out all the internal\n",
    "red points. Instead, we need two slices. The first involves points\n",
    "marked with `R`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        x x x x x x x\n",
    "        x R b R b R x\n",
    "        x b r b r b x\n",
    "        x R b R b R x\n",
    "        x b r b r b x\n",
    "        x R b R b R x\n",
    "        x x x x x x x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This slice is specified as `1::2` for `i` and `1::2` for `j`, or with\n",
    "`slice` objects:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = slice(1, None, 2);  j = slice(1, None, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second slice involves the red points with `R`:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        x x x x x x x\n",
    "        x r b r b r x\n",
    "        x b R b R b x\n",
    "        x r b r b r x\n",
    "        x b R b R b x\n",
    "        x r b r b r x\n",
    "        x x x x x x x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The slices are"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = slice(2, None, 2);  j = slice(2, None, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the black points, the first slice involves the `B` points:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        x x x x x x x\n",
    "        x r B r B r x\n",
    "        x b r b r b x\n",
    "        x r B r B r x\n",
    "        x b r b r b x\n",
    "        x r B r B r x\n",
    "        x x x x x x x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with slice objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = slice(2, None, 2);  j = slice(1, None, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The second set of black points is shown here:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "        x x x x x x x\n",
    "        x r b r b r x\n",
    "        x B r B r B x\n",
    "        x r b r b r x\n",
    "        x B r B r B x\n",
    "        x r b r b r x\n",
    "        x x x x x x x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "with slice objects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "i = slice(1, None, 2);  j = slice(2, None, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That is, we need four sets of slices. The simplest way of implementing\n",
    "the algorithm is to make a function with variables for the slices\n",
    "representing $i$, $i-1$, $i+1$, $j$, $j-1$, and $j+1$, here called\n",
    "`ic` (\"i center\"), `im1` (\"i minus 1\", `ip1` (\"i plus 1\"), `jc`, `jm1`,\n",
    "and `jp1`, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def update(u_, u_n, ic, im1, ip1, jc, jm1, jp1):\n",
    "    return \\\n",
    "       1.0/(1.0 + 2*theta*(Fx + Fy))*(theta*(\n",
    "           Fx*(u_[ip1,jc] + u_[im1,jc]) +\n",
    "           Fy*(u_[ic,jp1] + u_[ic,jm1])) +\\\n",
    "       u_n[ic,jc] + (1-theta)*(\n",
    "         Fx*(u_n[ip1,jc] - 2*u_n[ic,jc] + u_n[im1,jc]) +\\\n",
    "         Fy*(u_n[ic,jp1] - 2*u_n[ic,jc] + u_n[ic,jm1]))+\\\n",
    "         theta*dt*f_a_np1[ic,jc] + \\\n",
    "         (1-theta)*dt*f_a_n[ic,jc])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The formula returned from `update` is to be compared with\n",
    "([23](#diffu:2D:SOR3)).\n",
    "\n",
    "The relaxed Jacobi iteration can be implemented by"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "ic  = jc  = slice(1,-1)\n",
    "im1 = jm1 = slice(0,-2)\n",
    "ip1 = jp1 = slice(2,None)\n",
    "u_new[ic,jc] = update(\n",
    "    u_, u_n, ic, im1, ip1, jc, jm1, jp1)\n",
    "u[ic,jc] = omega*u_new[ic,jc] + (1-omega)*u_[ic,jc]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Gauss-Seidel (or SOR) updates need four different steps.\n",
    "The `ic` and `jc` slices are specified above. For each of these,\n",
    "we must specify the corresponding `im1`, `ip1`, `jm1`, and `jp1`\n",
    "slices. The code below contains the details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Red points\n",
    "ic  = slice(1,-1,2)\n",
    "im1 = slice(0,-2,2)\n",
    "ip1 = slice(2,None,2)\n",
    "jc  = slice(1,-1,2)\n",
    "jm1 = slice(0,-2,2)\n",
    "jp1 = slice(2,None,2)\n",
    "u_new[ic,jc] = update(\n",
    "    u_new, u_n, ic, im1, ip1, jc, jm1, jp1)\n",
    "\n",
    "ic  = slice(2,-1,2)\n",
    "im1 = slice(1,-2,2)\n",
    "ip1 = slice(3,None,2)\n",
    "jc  = slice(2,-1,2)\n",
    "jm1 = slice(1,-2,2)\n",
    "jp1 = slice(3,None,2)\n",
    "u_new[ic,jc] = update(\n",
    "    u_new, u_n, ic, im1, ip1, jc, jm1, jp1)\n",
    "\n",
    "# Black points\n",
    "ic  = slice(2,-1,2)\n",
    "im1 = slice(1,-2,2)\n",
    "ip1 = slice(3,None,2)\n",
    "jc  = slice(1,-1,2)\n",
    "jm1 = slice(0,-2,2)\n",
    "jp1 = slice(2,None,2)\n",
    "u_new[ic,jc] = update(\n",
    "    u_new, u_n, ic, im1, ip1, jc, jm1, jp1)\n",
    "\n",
    "ic  = slice(1,-1,2)\n",
    "im1 = slice(0,-2,2)\n",
    "ip1 = slice(2,None,2)\n",
    "jc  = slice(2,-1,2)\n",
    "jm1 = slice(1,-2,2)\n",
    "jp1 = slice(3,None,2)\n",
    "u_new[ic,jc] = update(\n",
    "    u_new, u_n, ic, im1, ip1, jc, jm1, jp1)\n",
    "\n",
    "# Relax\n",
    "c = slice(1,-1)\n",
    "u[c,c] = omega*u_new[c,c] + (1-omega)*u_[c,c]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function `solver_classic_iterative` in\n",
    "[`diffu2D_u0.py`](${src_diffu}/diffu2D_u0.py)\n",
    "contains a unified implementation of the relaxed Jacobi and SOR\n",
    "methods in scalar and vectorized versions using the techniques\n",
    "explained above.\n",
    "\n",
    "## Direct versus iterative methods\n",
    "<div id=\"diffu:2D:direct_vs_iter\"></div>\n",
    "\n",
    "### Direct methods\n",
    "\n",
    "There are two classes of methods for solving linear systems: direct methods\n",
    "and iterative methods. Direct methods are based on variants of the\n",
    "Gaussian elimination procedure and will produce an exact solution (in\n",
    "exact arithmetics) in an a priori known number of steps.\n",
    "Iterative methods, on the other hand, produce an approximate solution,\n",
    "and the amount of work for reaching a given accuracy is usually not\n",
    "known.\n",
    "\n",
    "\n",
    "The most common direct method today is to use the *LU factorization*\n",
    "procedure to factor the coefficient matrix $A$ as the product of a\n",
    "lower-triangular matrix $L$ (with unit diagonal terms)\n",
    "and an upper-triangular matrix $U$:\n",
    "$A=LU$. As soon as we have $L$ and $U$, a system of equations $LUc=b$\n",
    "is easy to solve because of the triangular nature of $L$ and $U$. We\n",
    "first solve $Ly=b$ for $y$ (forward substitution), and\n",
    "thereafter we find $c$ from solving $Uc=y$ (backward\n",
    "substitution).  When $A$ is a dense $N\\times N$ matrix, the LU\n",
    "factorization costs $\\frac{1}{3}N^3$ arithmetic operations, while the\n",
    "forward and backward substitution steps each require of\n",
    "the order $N^2$ arithmetic operations.\n",
    "That is, factorization dominates the costs, while the substitution steps are\n",
    "cheap.\n",
    "\n",
    "Symmetric, positive definite coefficient matrices often arise when\n",
    "discretizing PDEs. In this case, the LU factorization becomes $A=LL^T$,\n",
    "and the associated algorithm is known as *Cholesky factorization*.\n",
    "Most linear algebra software offers highly optimized implementations of\n",
    "LU and Cholesky factorization as well as forward and backward\n",
    "substitution (`scipy.linalg` is the relevant Python package).\n",
    "\n",
    "Finite difference discretizations lead to sparse coefficient matrices.\n",
    "An extreme case arose in the section [diffu:pde1:BE](#diffu:pde1:BE) where $A$ was\n",
    "tridiagonal. For a tridiagonal matrix, the amount of arithmetic\n",
    "operations in the LU and Cholesky factorization algorithms is just of\n",
    "the order $N$, not $N^3$. Tridiagonal matrices are special cases of\n",
    "*banded matrices*, where the matrices contain just a set of diagonal\n",
    "bands.  Finite difference methods on regularly numbered rectangular\n",
    "and box-shaped meshes give rise to such banded matrices, with 5 bands\n",
    "in 2D and 7 in 3D for diffusion problems.  Gaussian elimination only\n",
    "needs to work within the bands, leading to much more efficient\n",
    "algorithms.\n",
    "\n",
    "If $A_{i,j}=0$ for $j> i+p$ and $j< i-p$, $p$ is the *half-bandwidth*\n",
    "of the matrix. We have in our 2D problem $p=N_x+2$, while in 3D,\n",
    "$p=(N_x+1)(N_y+1)+2$. The cost of Gaussian elimination is then\n",
    "$\\Oof{Np^2}$, so with $p\\ll N$, we see that banded matrices are much\n",
    "more efficient to compute with. By reordering the unknowns in clever\n",
    "ways, one can reduce the work of Gaussian elimination\n",
    "further. Fortunately, the Python programmer has access to such\n",
    "algorithms through the `scipy.sparse.linalg` package.\n",
    "\n",
    "Although a direct method is an exact algorithm, rounding errors\n",
    "may in practice accumulate and pollute the solution. The effect\n",
    "grows with the size of the linear system, so both for accuracy and\n",
    "efficiency, iterative methods are better suited than direct methods\n",
    "for solving really large linear systems.\n",
    "\n",
    "\n",
    "### Iterative methods\n",
    "\n",
    "The Jacobi and SOR iterative methods belong to a class of iterative methods\n",
    "where the idea is to solve $Au=b$ by splitting A into two parts, $A=M-N$,\n",
    "such that solving systems $Mu=c$ is easy and efficient. With the splitting,\n",
    "we get a system"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Mu = Nu + b,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "which suggests an iterative method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "Mu^{r+1} = Nu^{r} + b,\\quad r=0,1,2,\\ldots,\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "where $u^{r+1}$ is a new approximation to $u$ in the $r+1$-th iteration. To\n",
    "initiate the iteration, we need a start vector $u^0$.\n",
    "\n",
    "The Jacobi and SOR methods are based on splitting $A$ into a lower\n",
    "tridiagonal part $L$, the diagonal $D$, and an upper tridiagonal part $U$,\n",
    "such that $A=L+D+U$. The Jacobi method corresponds to $M=D$ and $N=-L-U$.\n",
    "The Gauss-Seidel method employs $M=L+D$ and $N=-U$, while the SOR\n",
    "method corresponds to"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "M= \\frac{1}{\\omega}D + L,\\quad N = \\frac{1-\\omega}{\\omega}D - U\\thinspace .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relaxed Jacobi method has similar expressions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$\n",
    "M = \\frac{1}{\\omega}D,\\quad N = \\frac{1-\\omega}{\\omega}D - L - U\\thinspace .\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the matrix forms of the Jacobi and SOR methods as written above,\n",
    "we could in an implementation alternatively fill the matrix $A$ with\n",
    "entries and call general implementations of the Jacobi or SOR methods\n",
    "that work on a system $Au=b$. However, this is almost never done since\n",
    "forming the matrix $A$ requires quite some code and storing $A$ in the\n",
    "computer's memory is unnecessary. It is much easier to just apply the\n",
    "Jacobi and SOR ideas to the finite difference stencils directly in an\n",
    "implementation, as we have shown in detail.\n",
    "\n",
    "Nevertheless, the matrix formulation of the Jacobi and SOR methods have\n",
    "been important for analyzing their convergence behavior. One can show that\n",
    "the error $u^r-u$ fulfills $u^r-u = G^r(u^0-u)$, where $G=M^{-1}N$\n",
    "and $G^k$ is a matrix exponential. For the method to converge,\n",
    "$\\lim_{r\\rightarrow\\infty}||G^r||=0$ is a necessary and sufficient condition.\n",
    "This implies that the *spectral radius* of $G$ must be less than one.\n",
    "Since $G$ is directly related to the finite difference scheme for the\n",
    "underlying PDE problem, one can in principle compute the spectral radius.\n",
    "For a given PDE problem, however, this is not a practical strategy, since it\n",
    "is very difficult to develop useful formulas.\n",
    "Analysis of model problems, usually\n",
    "related to the Poisson equation,\n",
    "reveals some trends of interest: the convergence rate of the Jacobi\n",
    "method goes like $h^2$, while that of SOR with an optimal $\\omega$ goes\n",
    "like $h$, where $h$ is the spatial spacing: $h=\\Delta x=\\Delta y$.\n",
    "That is, the efficiency of the Jacobi method quickly deteriorates with\n",
    "the increasing mesh resolution, and SOR is much to be preferred\n",
    "(even if the optimal\n",
    "$\\omega$ remains an open question). We refer to\n",
    "Chapter 4 of [[Saad_2003]](#Saad_2003) for more information on the convergence theory.\n",
    "One important result is that if $A$ is symmetric and positive definite,\n",
    "then SOR will converge for any $0<\\omega <2$.\n",
    "\n",
    "The optimal $\\omega$ parameter can be theoretically established for\n",
    "a Poisson problem as"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- Equation labels as ordinary links -->\n",
    "<div id=\"_auto13\"></div>\n",
    "\n",
    "$$\n",
    "\\begin{equation}\n",
    "\\omega_{o} = \\frac{2}{1 + \\sqrt{1-\\varrho^2}},\\quad \\varrho = \\frac{\\cos(\\pi/N_x) + (\\Delta x/\\Delta y)^2\\cos(\\pi/N_y)}{1 + (\\Delta x/\\Delta y)^2}\\thinspace .\n",
    "\\label{_auto13} \\tag{25}\n",
    "\\end{equation}\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This formula can be used as a guide also in other problems.\n",
    "\n",
    "The Jacobi and the SOR methods have their great advantage of being\n",
    "trivial to implement, so they are obviously popular of this reason.\n",
    "However, the slow convergence of these methods limits the popularity to fairly\n",
    "small linear systems (i.e., coarse meshes). As soon as the matrix size\n",
    "grows, one is better off with more sophisticated iterative methods\n",
    "like the preconditioned Conjugate gradient method, which we now turn to.\n",
    "\n",
    "Finally, we mention that there is a variant of the SOR method, called the\n",
    "*Symmetric Successive Over-relaxation* method, known as SSOR, where\n",
    "one runs a standard SOR sweep through the mesh points and then a\n",
    "new sweep while visiting the points in reverse order.\n",
    "\n",
    "\n",
    "## The Conjugate gradient method\n",
    "<div id=\"diffu:2D:CG\"></div>\n",
    "\n",
    "There is no simple intuitive derivation of the Conjugate gradient\n",
    "method, so we refer to the many excellent expositions in the\n",
    "literature for the idea of the method and how the algorithm is\n",
    "derived. In particular, we recommend the books\n",
    "[[Templates_LA;@Axelsson_1996;@Saad_2003;@Greif_Ascher_2011]](#Templates_LA;@Axelsson_1996;@Saad_2003;@Greif_Ascher_2011).\n",
    "A brief overview is\n",
    "provided in the [Wikipedia article](https://en.wikipedia.org/wiki/Conjugate_gradient_method). Here, we\n",
    "just state the pros and cons of the method from a user's perspective\n",
    "and how we utilize it in code.\n",
    "\n",
    "The original Conjugate gradient method is limited to linear systems $Au=b$,\n",
    "where $A$ is a symmetric and positive definite matrix. There are, however,\n",
    "extensions of the method to non-symmetric matrices.\n",
    "<!-- , so when we use the -->\n",
    "<!-- term *Conjugate gradient method* hereafter, we usually mean the family of -->\n",
    "<!-- related methods that can be applied -->\n",
    "<!-- to most matrix systems arising from discretizing -->\n",
    "<!-- PDEs. When we need to distinuish between methods for -->\n",
    "<!-- the symmetric and non-symmetric -->\n",
    "<!-- cases, we use the terms *original Conjugate gradient method* and -->\n",
    "<!-- *conjugate gradient-like methods*, respectively. -->\n",
    "\n",
    "\n",
    "A major advantage of all conjugate gradient methods is that the matrix\n",
    "$A$ is only used in matrix-vector products, so we do not need form and\n",
    "store $A$ if we can provide code for computing a matrix-vector product\n",
    "$Au$.  Another important feature is that the algorithm is very easy to\n",
    "vectorize and parallelize.  The primary downside of the method is that\n",
    "it converges slowly unless one has an effective *preconditioner*\n",
    "for the system. That is, instead of solving $Au=b$, we try to solve\n",
    "$M^{-1}Au=M^{-1}b$ in the hope that the method works better for this\n",
    "*preconditioned* system. The matrix $M$ is the *preconditioner* or\n",
    "preconditioning matrix.  Now we need to perform matrix-vector products\n",
    "$y = M^{-1}Au$, which is done in two steps: first the matrix-vector\n",
    "product $v=Au$ is carried out and then the system $My=v$ must be\n",
    "solved.  Therefore, $M$ must be cheap to compute and systems $My=v$\n",
    "must be cheap to solve.\n",
    "\n",
    "A perfect preconditioner is $M=A$, but in each iteration in the\n",
    "Conjugate gradient method one then has so solve a system with $A$ as\n",
    "coefficient matrix! A key idea is to let $M$ be some kind of *cheap\n",
    "approximation* to $A$.  The simplest preconditioner is to set $M=D$,\n",
    "where $D$ is the diagonal of $A$. This choice means running one Jacobi\n",
    "iteration as preconditioner. [diffu:exer:splitting_prec](#diffu:exer:splitting_prec)\n",
    "shows that the Jacobi and SOR methods can also be viewed as\n",
    "preconditioners.\n",
    "\n",
    "Constructing good preconditioners is a scientific field on its\n",
    "own. Here we shall treat the topic just very briefly. For a user\n",
    "having access to the `scipy.sparse.linalg` library, there are\n",
    "Conjugate gradient methods and preconditioners readily available:\n",
    "\n",
    " * For positive definite, symmetric systems: `cg` (the Conjugate gradient method)\n",
    "\n",
    " * For symmetric systems: `minres` (Minimum residual method)\n",
    "\n",
    " * For non-symmetric systems:\n",
    "\n",
    "  * `gmres` (GMRES: Generalized minimum residual method)\n",
    "\n",
    "  * `bicg` (BiConjugate gradient method)\n",
    "\n",
    "  * `bicgstab` (Stabilized BiConjugate gradient method)\n",
    "\n",
    "  * `cgs` (Conjugate gradient squared method)\n",
    "\n",
    "  * `qmr` (Quasi-minimal residual iteration)\n",
    "\n",
    "\n",
    " * Preconditioner: `spilu` (Sparse, incomplete LU factorization)\n",
    "\n",
    "The ILU preconditioner is an attractive all-round type of\n",
    "preconditioner that is suitable for most problems on serial\n",
    "computers. A more efficient preconditioner is the multigrid method,\n",
    "and algebraic multigrid is also an all-round choice as\n",
    "preconditioner. The Python package [PyAMG](https://github.com/pyamg/pyamg) offers efficient implementations of\n",
    "the algebraic multigrid method, to be used both as a preconditioner\n",
    "and as a stand-alone iterative method.\n",
    "\n",
    "The matrix arising from implicit time discretization methods applied to the\n",
    "diffusion equation is symmetric and positive definite. Thus, we can use\n",
    "the Conjugate gradient method (`cg`), typically in combination with an\n",
    "ILU preconditioner. The code is very similar to the one we created\n",
    "when solving the linear system by sparse Gaussian elimination, the\n",
    "main difference is that we now allow for calling up the Conjugate\n",
    "gradient function as an alternative solver."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def solver_sparse(\n",
    "    I, a, f, Lx, Ly, Nx, Ny, dt, T, theta=0.5,\n",
    "    U_0x=0, U_0y=0, U_Lx=0, U_Ly=0, user_action=None,\n",
    "    method='direct', CG_prec='ILU', CG_tol=1E-5):\n",
    "    \"\"\"\n",
    "    Full solver for the model problem using the theta-rule\n",
    "    difference approximation in time. Sparse matrix with\n",
    "    dedicated Gaussian elimination algorithm (method='direct')\n",
    "    or ILU preconditioned Conjugate Gradients (method='CG' with\n",
    "    tolerance CG_tol and preconditioner CG_prec ('ILU' or None)).\n",
    "    \"\"\"\n",
    "    # Set up data structures as shown before\n",
    "\n",
    "    # Precompute sparse matrix\n",
    "    ...\n",
    "\n",
    "    A = scipy.sparse.diags(\n",
    "        diagonals=[main, lower, upper, lower2, upper2],\n",
    "        offsets=[0, -lower_offset, lower_offset,\n",
    "                 -lower2_offset, lower2_offset],\n",
    "        shape=(N, N), format='csc')\n",
    "\n",
    "    if method == 'CG':\n",
    "        if CG_prec == 'ILU':\n",
    "            # Find ILU preconditioner (constant in time)\n",
    "            A_ilu = scipy.sparse.linalg.spilu(A)  # SuperLU defaults\n",
    "            M = scipy.sparse.linalg.LinearOperator(\n",
    "                shape=(N, N), matvec=A_ilu.solve)\n",
    "        else:\n",
    "            M = None\n",
    "        CG_iter = []  # No of CG iterations at time level n\n",
    "\n",
    "    # Time loop\n",
    "    for n in It[0:-1]:\n",
    "        # Compute b, vectorized version\n",
    "\n",
    "        # Solve matrix system A*c = b\n",
    "        if method == 'direct':\n",
    "            c = scipy.sparse.linalg.spsolve(A, b)\n",
    "        elif method == 'CG':\n",
    "            x0 = u_n.T.reshape(N)  # Start vector is u_n\n",
    "            CG_iter.append(0)\n",
    "\n",
    "            def CG_callback(c_k):\n",
    "                \"\"\"Trick to count the no of iterations in CG.\"\"\"\n",
    "                CG_iter[-1] += 1\n",
    "\n",
    "            c, info = scipy.sparse.linalg.cg(\n",
    "                A, b, x0=x0, tol=CG_tol, maxiter=N, M=M,\n",
    "                callback=CG_callback)\n",
    "\n",
    "        # Fill u with vector c\n",
    "        # Update u_n before next step\n",
    "        u_n, u = u, u_n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The number of iterations in the Conjugate gradient method is of interest,\n",
    "but is unfortunately not available from the `cg` function. Therefore,\n",
    "we perform a trick: in each iteration a user function `CG_callback`\n",
    "is called where we accumulate the number of iterations in a list\n",
    "`CG_iter`.\n",
    "\n",
    "## What is the recommended method for solving linear systems?\n",
    "\n",
    "There is no clear answer to this question. If you have enough memory\n",
    "and computing time available, direct methods such as `spsolve` are\n",
    "to be preferred since they are easy to use and finds almost an exact\n",
    "solution. However, in larger 2D and in 3D problems, direct methods\n",
    "usually run too slowly or require too much memory, so one is forced\n",
    "to use iterative methods. The fastest and most reliable methods are\n",
    "in the Conjugate Gradient family, but these require suitable\n",
    "preconditioners. ILU is an all-round preconditioner, but it is not\n",
    "suited for parallel computing. The Jacobi and SOR iterative methods\n",
    "are easy to implement, and popular for that reason, but run slowly. Jacobi\n",
    "iteration is not an option in real problems, but SOR may be.\n",
    "<!-- As we have showed, Jacobi is equivalent to running a Forward Euler scheme -->\n",
    "<!-- until the stationary state is reached -->"
   ]
  }
 ],
 "metadata": {},
 "nbformat": 4,
 "nbformat_minor": 4
}
